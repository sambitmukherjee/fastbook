{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAt7ZHA5Clxg",
        "outputId": "a9a05860-e5aa-41bb-90fd-38aff77a97c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AMrsOYxgClxp"
      },
      "outputs": [],
      "source": [
        "from fastbook import *\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMrN69cwDdg0",
        "outputId": "22374aea-2288-487a-8341-7725b7703193"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/content/gdrive/My Drive')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37EvT2LXDeYY",
        "outputId": "37958b08-dc14-422b-a7c6-00d9faeca792"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/content/gdrive/My Drive/Colab Notebooks/fastbook/clean')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "course_path = gdrive/'Colab Notebooks/fastbook/clean'\n",
        "course_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBK8dpwJClxp"
      },
      "source": [
        "# NLP Deep Dive: RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3eF8dUPClxq"
      },
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2lIobySClxr"
      },
      "source": [
        "### Word Tokenization with fastai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.text.all import *"
      ],
      "metadata": {
        "id": "lLn5O5NQYNld"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URLs.IMDB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o6QzWQMcYRWZ",
        "outputId": "b3cdce9e-c851-4d59-b997-d6073defd5d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://s3.amazonaws.com/fast-ai-nlp/imdb.tgz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.IMDB)\n",
        "path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "MSOFGLzhYXmB",
        "outputId": "745f28c3-d714-4679-b436-27d8c72b3ca4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='144441344' class='' max='144440600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [144441344/144440600 00:02&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/imdb')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = get_text_files(path, folders=['train', 'test', 'unsup'])\n",
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kWc9U4IYpYw",
        "outputId": "39fa48c8-5a2d-4212-b456-0d9e88ef1005"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#100000) [Path('/root/.fastai/data/imdb/train/neg/10026_2.txt'),Path('/root/.fastai/data/imdb/train/neg/703_4.txt'),Path('/root/.fastai/data/imdb/train/neg/1041_1.txt'),Path('/root/.fastai/data/imdb/train/neg/5879_1.txt'),Path('/root/.fastai/data/imdb/train/neg/6649_1.txt'),Path('/root/.fastai/data/imdb/train/neg/8775_3.txt'),Path('/root/.fastai/data/imdb/train/neg/5304_2.txt'),Path('/root/.fastai/data/imdb/train/neg/7561_2.txt'),Path('/root/.fastai/data/imdb/train/neg/6231_4.txt'),Path('/root/.fastai/data/imdb/train/neg/5398_1.txt')...]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(files[0], 'r') as f:\n",
        "    txt = f.read()\n",
        "txt[:75]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3bNFZsZxYzIK",
        "outputId": "6cd571f0-9a0e-4e91-cc0a-26b03c9cfec3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I had some expectation for the movie, since it had a nice star cast and it '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLx_P_OgYBSL"
      },
      "source": [
        "---\n",
        "\n",
        "Demo of `coll_repr`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(range(10))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym6dqbDEZPpz",
        "outputId": "c3311c90-9794-4792-c0eb-369a2328de12"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coll_repr(x, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LoVXIzy-ZWmt",
        "outputId": "8c455c04-ea04-4820-d541-913917744888"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(#10) [0,1,2...]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coll_repr(x, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UVw7P6qLZTeR",
        "outputId": "e9e9fcf2-5a51-46ec-f035-53c9ebc91571"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(#10) [0,1,2,3,4...]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(coll_repr(x, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiJKhwsJZZLE",
        "outputId": "be5b501f-b3f3-4055-adaf-21e779265317"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(coll_repr(x, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC7zDkOrZg2l",
        "outputId": "cf4ac182-bade-4db9-b7ed-87d0c7df9fce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#10) [0,1,2,3,4...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YEWdq2eYWEY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy = WordTokenizer()\n",
        "type(spacy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "r-Bh0Vb8aANP",
        "outputId": "d5a89090-b136-44b4-c2eb-359cfbad0713"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fastai.text.core.SpacyTokenizer"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>fastai.text.core.SpacyTokenizer</b><br/>def __call__(items)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/fastai/text/core.py</a>Spacy tokenizer for `lang`</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 113);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(spacy([txt]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rirXqoVMaH4I",
        "outputId": "489d9f41-4116-45d9-e9ed-d0383fb19235"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generator"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The generator generates a list of tokens for each string. If we pass a list with more than one string, then we'll get back more than one list."
      ],
      "metadata": {
        "id": "8kaHVkR7GBeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(first)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWPPFY68aZUH",
        "outputId": "cc9987bd-4b7f-4e0e-e8d4-737d5f3274a0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function first in module fastcore.basics:\n",
            "\n",
            "first(x, f=None, negate=False, **kwargs)\n",
            "    First element of `x`, optionally filtered by `f`, or None if missing\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toks = first(spacy([txt]))\n",
        "print(coll_repr(toks, 30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaqw3693adUL",
        "outputId": "e1054d9d-b5c0-4595-a4af-f4e065c344ed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#272) ['I','had','some','expectation','for','the','movie',',','since','it','had','a','nice','star','cast','and','it','is','the','return','of','the','duo','of','Akshay','and','Saif','.','Well',','...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first(spacy(['The U.S. dollar $1 is $1.00.']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKqUzrseao5U",
        "outputId": "0c77d440-6d10-4ac1-9c74-779943007ee9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9) ['The','U.S.','dollar','$','1','is','$','1.00','.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tkn = Tokenizer(spacy)\n",
        "type(tkn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "nLQLDOtnbCKz",
        "outputId": "5b0fd4cc-5a93-4196-fd24-e416b9a5d24e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fastai.text.core.Tokenizer"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>fastai.text.core.Tokenizer</b><br/>def __call__(x, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/fastai/text/core.py</a>Provides a consistent `Transform` interface to tokenizers operating on `DataFrame`s and folders</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 257);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tkn(txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "uio3tmFTbR8t",
        "outputId": "540baffe-d5f1-4f5a-9bdb-a23ef59d59fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fastcore.foundation.L"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>fastcore.foundation.L</b><br/>def __call__(cls, x=None, *args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/fastcore/foundation.py</a>Behaves like a list of `items` but can also index with list of indices or masks</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 101);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbKr8_xtajNC"
      },
      "source": [
        "Notice two differences between `spacy` and `tkn`:\n",
        "\n",
        "1. `spacy` accepts a collection of strings, whereas `tkn` accepts a single string.\n",
        "2. `spacy` returns a generator, whereas `tkn` returns an `L` object."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(coll_repr(tkn(txt), 31))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7c4owV2baDz",
        "outputId": "5b703798-30dd-4d5a-d74d-3f3135e4f397"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#297) ['xxbos','i','had','some','expectation','for','the','movie',',','since','it','had','a','nice','star','cast','and','it','is','the','return','of','the','duo','of','xxmaj','akshay','and','xxmaj','saif','.'...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "defaults.text_proc_rules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGp2EG5kblMt",
        "outputId": "0ccff3f1-02c2-44ef-9350-1ce5ad64631d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<function fastai.text.core.fix_html(x)>,\n",
              " <function fastai.text.core.replace_rep(t)>,\n",
              " <function fastai.text.core.replace_wrep(t)>,\n",
              " <function fastai.text.core.spec_add_spaces(t)>,\n",
              " <function fastai.text.core.rm_useless_spaces(t)>,\n",
              " <function fastai.text.core.replace_all_caps(t)>,\n",
              " <function fastai.text.core.replace_maj(t)>,\n",
              " <function fastai.text.core.lowercase(t, add_bos=True, add_eos=False)>]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "??replace_rep"
      ],
      "metadata": {
        "id": "Wr2PIgMAcgAW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coll_repr(tkn('&copy;   Fast.ai www.fast.ai/INDEX'), 31)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IzmjcOTmdXdk",
        "outputId": "a7c7557c-6cf0-4ee2-b97f-054ba745a8e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"(#11) ['xxbos','©','xxmaj','fast.ai','xxrep','3','w','.fast.ai','/','xxup','index']\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osGhHOS3Clxv"
      },
      "source": [
        "### Subword Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txts = []\n",
        "for o in files[:2000]:\n",
        "    with open(o, 'r') as f:\n",
        "        txts.append(f.read())\n",
        "txts = L(txts)\n",
        "txts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0CaRfSpec2p",
        "outputId": "c2d3d378-7c05-4d69-8151-8f94f48f8982"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2000) [\"I had some expectation for the movie, since it had a nice star cast and it is the return of the duo of Akshay and Saif. Well, I was hesitant to watch the movie because this was done by the same man who wrote the story for Dhoom franchise because I hated Dhoom 2; but if Dhoom 2 is compared to Tashan, I would say Dhoom 2 is very realistic. <br /><br />When I saw the credits at the beginning, I felt nice because it was put up in a nice way. Well, the very first scene itself pis*ed me off. Then, the major drawback of the movie is the action sequences. Me and my friends were laughing our guts off watching this crappy fights. It was like Akshay against some 30 thugs and all and the thugs even got machine guns! Phew...you got to see this to understand how bad the action sequences are.<br /><br />The other thing about the movie is the far too predictable story. It reminded me of some of the early 80's movies.<br /><br />Well, the only thing the movie is worth is of sexy Kareena, who looked really hot in this one.And for that, I give a rating of 2 out of 10.<br /><br />Guys, please..please...don't see this one thinking that it is a real gangster movie. Well, you can watch this to have some laughs at the terrible fight scenes.<br /><br />Thats all.\",\"College students, who are clearing out a condemned dormitory, are stalked by an elusive killer.<br /><br />The Dorm That Dripped Blood (aka Pranks) is a bit of a mixed bag for slasher fans. The movies production values are pretty low and the story for the most part is pretty routine, there's even a creepy bum hanging around for a red herring. In fact much of the story's build-up is pretty forgettable, save for one or two brutal murders. But the movie is really made better by its surprisingly intense climax (in an atmospheric setting) and one fairly bold, unconventional conclusion.<br /><br />The cast is lackluster for the most part. Stephen Sachs is the best of the lot as he does a pretty nice turn in character. Also look for a young Daphne Zuniga as an ill-fated student.<br /><br />Over all this is a pretty standard B slasher effort, but the finale is well worth savoring and for this viewer saved the movie from being a complete ho-hum.<br /><br />** out of ****\",'How many more of those fake \"slice of life\" movies need to be made? Hopefully not too many.<br /><br />Raising Victor Vargas is a very self-conscious attempt by the director Peter Solett at garnering the attention of Hollywood. Nothing wrong with that in general. What is wrong with this film in particular is that it ignores the audience and piles on every cliché in the book of supposedly \"edgy\" Hollywood independent production.<br /><br />It\\'s supposed to be \"real\" so left shake the camera \"documentary style\", except no documentarian would shake the camera on purpose...<br /><br />It\\'s \"edgy\" so let\\'s not waste any time lighting the film.<br /><br />It\\'s \"hip\", so let\\'s have the children use swear words like Al Pacino in Scarface...<br /><br />And so on, and so forth. All that you are left with is a very self-conscious attempt at impressing Hollywood that won\\'t impress anyone outside of the \"rarefied\" indie crowd that seems to still heap acclaim on every bad film.',\"I wonder how the actors acted in this movie. Annette Bening was really herself, half in and half out, was she faking or being natural? It didn't make any difference considering that even if she had been walking on the ceiling it would not have changed the pattern of the film. Brian Cox acted really well. I almost thought that he had always acted this way, tricky, dishonest, in a dirty surrounding where nobody really cared about hygiene. As for Gwyneth Paltrow, the question is what she was doing in this film.<br /><br />This film is quite sickening and disgusting. Who would pay to see such a crap?\",'OK, anyone who could honestly say that this movie was Great or even Good is either delusional or knows the Director, Writer and Producers and is trying to boost the buzz on this film. I watched the movie because a friend of mine worked on it and it was Horrible. I\\'m an actress and have worked in the industry for a while now on big films and even independents and this movie bored me to tears. The reason I\\'m being so harsh is because this film was clearly a different take on \"Of Mice and Men\" and they should sue because it is such a horrible rip-off of the story. In an industry where Hollywood seems to be creatively bankrupt...for someone to take a classic book and film \"Of Mice and Men\" and destroy it with a new spin bugs me so much. The actors, the accents, the dialog and the direction were amateurish and the writing was dismal. I mean if your going to take a new spin on an existing story make sure its just as good or better than the original to make the new spin justified. Did not like this movie at all.','LOC could have been a very well made movie on how the Kargil war was fought; it had the locations, the budget, and the skill to have been India\\'s \"Saving Private Ryan\" or \"Black Hawk Down\". Instead it come across as a bloated, 4 hour bore of trying to meld the war move with the masala movie. Even the war scenes were terribly executed, using the same hill in all their battle scenes, and spending unnecessary time on casual talk. Instead of trying to appeal to the indian public, a better movie would have been a to-the-book account of what happened at Kargil (like \"Black Hawk Down\") or even spending time on the militant point of view (like \"Tora, Tora, Tora\"). Even better, it could have used a competent director like Ram Gopal Verma to write, direct and edit the film. Until then, I\\'d like to see some one re-edit this film, with only the pertinent portions included; it would make the movie more watchable.','I am not one of those people that will walk out of a movie that was based on source material and automatically say, \"The book was better.\" I know better than to demote the value of a movie just because it wasn\\'t a faithful adaptation. There is a lengthy process and lots of decisions that go into making a movie that are sometimes out of the director\\'s/editor\\'s/cinematographer\\'s/producer\\'s control and certainly out of the original author\\'s control. Therefore, it is unreasonable to expect a movie to be exactly the same, word for word, as a book or play or video game or Disneyland Ride, or whatever! A movie should be judged on its own standard and how it fits in society. Moreover, a successful movie should be made because the material is relevant to the society which it belongs and, if it is based on source material, its relevance needs to be reexamined and enhanced by the filmmakers. <br /><br />Films like There Will Be Blood follow this paradigm because while it was based on a novel written at the turn of the century, Oil!, it feels relevant because of things like the Iraq war and energy concerns that the film\\'s country of origin, the US, was and is experiencing. Even King Kong, based on the original film, benefits from using new technology and concerns of animal rights that people have.<br /><br />With that said, I just don\\'t understand why they even bothered to make this movie? Besides the great performances, guaranteed Oscar nods and Shanley\\'s director/writers fee and royalties he will get, this movie seems to come from nowhere. It should have simply stayed as a play. The movie (which is essentially the same as the play) says nothing new about the reprehensible sexual atrocities committed and in many cases covered up by the Catholic church here and abroad. It says nothing new or different than the original play. I can\\'t help but compare this movie to another movie that came out at around the same time: Frost/Nixon, which was also based on a play. Frost/Nixon, while about Nixon\\'s regrets, seems relevant because it seems to have come at a time when President Bush was about to leave office. The regrets that Nixon had, as depicted in the play/movie, about the war and his presidency could just as easily reflected on Bush and his presidency. In that respect Frost/Nixon seemed more relevant and actually benefited from a wider distribution via film because it got people talking and reflecting about the political status quo in the country at the time. In contrast, Doubt felt like it was yesterday\\'s news and didn\\'t seem to offer anything that the play didn\\'t offer.<br /><br />Of course the movie is \"good,\" the performances are outstanding, and the screenplay adaptation is apt, but so what? Why didn\\'t it just stay as a play? Why, besides marketing and financial reasons, make it into a movie? It gave audiences nothing new to discus about the awful subject.',\"Anyone not aware of the 1973 original British Lion movie ' The Wicker Man' would,no doubt, have left the cinema with the impression 'Poor' and 'Peurile'.<br /><br />As a devotee of the original I left with the impression Purely Poor.<br /><br />From the grim reality of haggle toothed inbreds drawing the force of law and order into a web of paganistic barbaric ritual on a remote Scottish island, named Summerisle(the original) to a near Amazon-ic colony off the Maine coast of the US, named Summersisle, the remake hardly hits the spot.<br /><br />This is, quite sadly, a case of what 'could' have been a classic remake of a classic being tampered with to cater for a simple minded public. NOTHING MORE AND NOTHING LESS. <br /><br />Gentlemen (or given the reworked context of the film) Ladies involved ... hang your heads in shame.\",\"All the ingredients of low-brow b-movie cult cinema. Topless (and bottomless) girls, kung-fu kicking chefs, slave traders, evil Germans with mustaches, Cameron Mitchell and sword-wielding zombies.<br /><br />And, of course the breasts of Camille Keaton, who's best known display occurs in the feminist exploitation classic I Spit on Your Grave. We also must mention the hooters of jewel Shepard, who play a hooker in the recent film The Cooler.<br /><br />Lots of blood and action with knives and swords and martial arts among topless dancers in a bar, in a whorehouse, and on a boat load of martial artists heading to some zombie island where bad martial artists go to die or something like that.<br /><br />Tops and bottoms come off easily and frequently as travelers are well lubricated thanks to the boat owner.<br /><br />Then disaster strikes as their boat is destroyed and they land on the zombie island where mas monks sacrifice young girls to the dead martial artists to bring them back to life.<br /><br />Just when you thought it had everything, there are piranhas in the water. Yum Yum A big fat German for dinner.<br /><br />Just the thing for your next zombie fest.\",'This self-indulgent mess may have put the kibosh on Mr. Branagh\\'s career as an adapter of Shakespeare for the cinema. (Released 4 years ago; not a peep of an adaptation since.) I just finished watching this on cable -- holy God, it\\'s terrible.<br /><br />I agree with the sentiment of a reviewer below who said that reviewing something so obviously and sadly awful is an ungenerous act that comes across as shrill. That being said, I\\'ll take the risk, if only because *Love\\'s Labour\\'s Lost* is the perfect reward for those who overrated Mr. Branagh\\'s directorial abilities in the past. Branagh has always been a pretty lousy director: grindingly literal-minded; star-struck; unforgivably ungenerous to his fellow actors (he loves his American stars, but loves himself more, making damn sure that he gets all the good lines).<br /><br />Along those lines, the sad fact remains that *Love\\'s Labour\\'s Lost* is scarcely worse than the interminable, ghastly, bloated *Hamlet* from 1996. In fact, this film may be preferable, if only because it\\'s about 1/3 the length. Branagh decided it would be a good idea to update this bad early work of Shakespeare\\'s to the milieu of Cole Porter, George Gershwin, Fred Astaire, yada yada. So he sets the thing in 1939, leaves about an eighth of the text intact in favor of egregious interpretations of Thirties\\' standards (wait till you see the actors heaved up on wires toward the ceiling during \"I\\'m In Heaven\"), and casts actors not known for their dancing or singing (himself included). The result is a disaster so surreal that one is left dumbfounded that they just didn\\'t call a horrified stop to the whole thing after looking at the first dailies. I don\\'t even blame the cast. To paraphrase Hamlet, \"The screenplay\\'s the thing!\" NO ONE could possibly come off well in this hodge-podge: the illustrious RSC alumni fare no better than Alicia Silverstone. Who could possibly act in this thing?<br /><br />Branagh\\'s first mistake was in thinking that *Love\\'s Labour\\'s Lost* was a play worth filming. Trust me, it isn\\'t. It\\'s an anomaly in the Bard\\'s canon, written expressly for an educated coterie of courtiers -- NOT the usual audience for which he wrote. Hence, there\\'s a lot of precious (and TEDIOUS!) word-play, references to contemporary scholastic nonsense, parodies of Lyly\\'s *Euphues* . . . in other words, hardly the sort of material to appeal to a broad audience. Hell, it doesn\\'t appeal to an audience already predisposed to Shakespearean comedy. The play cannot be staged without drastically cutting the text and desperately \"updating\" it with any gimmick that comes to hand. Which begs the question, Why bother?<br /><br />Branagh\\'s second mistake was in thinking that Shakespeare\\'s cream-pie of a play could be served with a side-order of Gershwin\\'s marmalade. Clearly the idea, or hope, was to make an unintelligible Elizabethan exercise palatable for modern audiences by administering nostalgic American pop culture down their throats at the same time. But again, this begs the question, Why bother?<br /><br />'...]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp = SubwordTokenizer(vocab_sz=1000)\n",
        "type(sp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "DmGJhg3peuO1",
        "outputId": "55b85f1c-defc-4d52-eeb6-f9cdcaf92b6b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fastai.text.core.SentencePieceTokenizer"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>fastai.text.core.SentencePieceTokenizer</b><br/>def __call__(items)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/fastai/text/core.py</a>SentencePiece tokenizer for `lang`</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 321);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that SentencePiece is a common choice is multi-lingual models (such as XLMRoBERTa)."
      ],
      "metadata": {
        "id": "LUymjMzUfKNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp.setup(txts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XXCtlRs4fAYD",
        "outputId": "d9a21b86-f089-4967-ee38-e25237cd549a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sp_model': Path('tmp/spm.model')}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktK4KksTMsw0"
      },
      "source": [
        "**Note:** We're passing in a list of strings to `setup`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(sp([txt]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjbcAbyhfXkh",
        "outputId": "e2a6e59a-9b5c-46f6-e759-d069e36d85e1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generator"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toks = first(sp([txt]))\n",
        "print(coll_repr(toks, 40))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmDJeUZzfc0S",
        "outputId": "382f5634-2d50-4d9a-cf8a-4226f62d8f32"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#418) ['▁I','▁had','▁some','▁expect','ation','▁for','▁the','▁movie',',','▁since','▁it','▁had','▁a','▁nice','▁star','▁cast','▁and','▁it','▁is','▁the','▁re','t','ur','n','▁of','▁the','▁du','o','▁of','▁A','k','s','ha','y','▁and','▁S','a','if','.','▁Well'...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def subword(sz):\n",
        "    sp = SubwordTokenizer(vocab_sz=sz)\n",
        "    sp.setup(txts)\n",
        "    return ' '.join(first(sp([txt]))[:40])"
      ],
      "metadata": {
        "id": "FhNL24qpfouD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subword(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UoClw5kUgC_v",
        "outputId": "0a8aca88-2e8d-4a4c-912d-8a2b41925af2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁I ▁had ▁some ▁expect ation ▁for ▁the ▁movie , ▁since ▁it ▁had ▁a ▁nice ▁star ▁cast ▁and ▁it ▁is ▁the ▁re t ur n ▁of ▁the ▁du o ▁of ▁A k s ha y ▁and ▁S a if . ▁Well'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subword(200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u-52ipuMgNcr",
        "outputId": "1fac4aad-8091-43c6-ca8a-cba34199a9df"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁I ▁ h a d ▁some ▁ex p e c t a tion ▁for ▁the ▁movie , ▁s in ce ▁it ▁ h a d ▁a ▁ n ic e ▁s t ar ▁c a s t ▁and ▁it ▁is'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subword(10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_KF-jNdpgXLO",
        "outputId": "5d4891f5-dd65-4d85-86c2-dd5ecc5ebd1b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁I ▁had ▁some ▁expect ation ▁for ▁the ▁movie , ▁since ▁it ▁had ▁a ▁nice ▁star ▁cast ▁and ▁it ▁is ▁the ▁return ▁of ▁the ▁duo ▁of ▁Akshay ▁and ▁Sa if . ▁Well , ▁I ▁was ▁he s it ant ▁to ▁watch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPFWk7UOClxx"
      },
      "source": [
        "### Numericalization with fastai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toks = tkn(txt)\n",
        "print(coll_repr(toks, 31))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdEEZfN8RQ0e",
        "outputId": "13034ab3-bdbc-4394-c3cc-a8582e43e6bc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(#297) ['xxbos','i','had','some','expectation','for','the','movie',',','since','it','had','a','nice','star','cast','and','it','is','the','return','of','the','duo','of','xxmaj','akshay','and','xxmaj','saif','.'...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reminder:\n",
        "type(txts), len(txts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXgdYdfLRWPC",
        "outputId": "ba37a11b-1429-4a3d-a768-3c176cb381b6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(fastcore.foundation.L, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toks200 = txts[:200].map(tkn)\n",
        "toks200[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UmT3gKtRt1t",
        "outputId": "13763a4b-ce88-40af-89a5-516894686501"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#297) ['xxbos','i','had','some','expectation','for','the','movie',',','since'...]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = Numericalize()\n",
        "type(num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "Gdfyqo_BR1re",
        "outputId": "6249657c-f835-42fe-88f6-ac4b65b1d775"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fastai.text.data.Numericalize"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>fastai.text.data.Numericalize</b><br/>def __call__(x, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/fastai/text/data.py</a>Reversible transform of tokenized texts to numericalized ids</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 35);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** When instantiating `Numericalize`, we can specify `min_freq` and `max_vocab`. The reason is that the spaCy tokenizer doesn't create a vocab with a fixed number of tokens. It also doesn't set a minimum frequency. But SentencePiece has a fixed vocabulary size!"
      ],
      "metadata": {
        "id": "vm5fDDvNf46q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num.setup(toks200)"
      ],
      "metadata": {
        "id": "PoPWoDe8SJSY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmzWgtUeNAnV"
      },
      "source": [
        "**Note:** We're passing in a list of lists of tokens to `setup`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(num.vocab), len(num.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-dXyhHjSNtq",
        "outputId": "2c38d283-8b23-411d-e0dd-c7596e3a3e05"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 2152)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The length of the vocab is less because we only used 200 texts to set it up."
      ],
      "metadata": {
        "id": "LpOTBhA9SaIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coll_repr(num.vocab, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uENULKqRSjW_",
        "outputId": "0101aa8d-02c8-4b65-f1ef-43cb47683158"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"(#2152) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the',',','.','and','a','of','to','is','it','i','this'...]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nums = num(toks)[:20]\n",
        "nums"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONQuBFWYTkob",
        "outputId": "f0acc0d1-89a5-4d97-be69-962de43c298d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorText([  2,  18,  77,  66,   0,  28,   9,  26,  10, 276,  17,  77,  13, 556, 335, 182,  12,  17,  16,   9])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(num.vocab[o] for o in nums)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Dvuy8Sd0TooS",
        "outputId": "011fba4d-934f-4ec3-b7c4-996301868689"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxbos i had some xxunk for the movie , since it had a nice star cast and it is the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiygXiOXClxz"
      },
      "source": [
        "### Putting Our Texts into Batches for a Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "jF2lYmbfClxz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "88f052ac-1e03-4613-8a74-4243f3d10a9e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>back</td>\n",
              "      <td>over</td>\n",
              "      <td>the</td>\n",
              "      <td>example</td>\n",
              "      <td>of</td>\n",
              "      <td>classifying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>movie</td>\n",
              "      <td>reviews</td>\n",
              "      <td>we</td>\n",
              "      <td>studied</td>\n",
              "      <td>in</td>\n",
              "      <td>chapter</td>\n",
              "      <td>1</td>\n",
              "      <td>and</td>\n",
              "      <td>dig</td>\n",
              "      <td>deeper</td>\n",
              "      <td>under</td>\n",
              "      <td>the</td>\n",
              "      <td>surface</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>first</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>look</td>\n",
              "      <td>at</td>\n",
              "      <td>the</td>\n",
              "      <td>processing</td>\n",
              "      <td>steps</td>\n",
              "      <td>necessary</td>\n",
              "      <td>to</td>\n",
              "      <td>convert</td>\n",
              "      <td>text</td>\n",
              "      <td>into</td>\n",
              "      <td>numbers</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>how</td>\n",
              "      <td>to</td>\n",
              "      <td>customize</td>\n",
              "      <td>it</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>by</td>\n",
              "      <td>doing</td>\n",
              "      <td>this</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>'ll</td>\n",
              "      <td>have</td>\n",
              "      <td>another</td>\n",
              "      <td>example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>the</td>\n",
              "      <td>preprocessor</td>\n",
              "      <td>used</td>\n",
              "      <td>in</td>\n",
              "      <td>the</td>\n",
              "      <td>data</td>\n",
              "      <td>block</td>\n",
              "      <td>xxup</td>\n",
              "      <td>api</td>\n",
              "      <td>.</td>\n",
              "      <td>\\n</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>then</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>will</td>\n",
              "      <td>study</td>\n",
              "      <td>how</td>\n",
              "      <td>we</td>\n",
              "      <td>build</td>\n",
              "      <td>a</td>\n",
              "      <td>language</td>\n",
              "      <td>model</td>\n",
              "      <td>and</td>\n",
              "      <td>train</td>\n",
              "      <td>it</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>while</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Just run:\n",
        "stream = \"In this chapter, we will go back over the example of classifying movie reviews we studied in chapter 1 and dig deeper under the surface. First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the PreProcessor used in the data block API.\\nThen we will study how we build a language model and train it for a while.\"\n",
        "tokens = tkn(stream)\n",
        "bs,seq_len = 6,15\n",
        "d_tokens = np.array([tokens[i*seq_len:(i+1)*seq_len] for i in range(bs)])\n",
        "df = pd.DataFrame(d_tokens)\n",
        "display(HTML(df.to_html(index=False,header=None)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "TzDY_SEuClxz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "49555eeb-09f2-470d-e639-99058a24e431"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>movie</td>\n",
              "      <td>reviews</td>\n",
              "      <td>we</td>\n",
              "      <td>studied</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>first</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>look</td>\n",
              "      <td>at</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>how</td>\n",
              "      <td>to</td>\n",
              "      <td>customize</td>\n",
              "      <td>it</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>the</td>\n",
              "      <td>preprocessor</td>\n",
              "      <td>used</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>will</td>\n",
              "      <td>study</td>\n",
              "      <td>how</td>\n",
              "      <td>we</td>\n",
              "      <td>build</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Just run:\n",
        "bs,seq_len = 6,5\n",
        "d_tokens = np.array([tokens[i*15:i*15+seq_len] for i in range(bs)])\n",
        "df = pd.DataFrame(d_tokens)\n",
        "display(HTML(df.to_html(index=False,header=None)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "jJ-jZp--Clxz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "30b43993-7a53-4ba1-c46a-20c9ef4f0ded"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>chapter</td>\n",
              "      <td>1</td>\n",
              "      <td>and</td>\n",
              "      <td>dig</td>\n",
              "      <td>deeper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>the</td>\n",
              "      <td>processing</td>\n",
              "      <td>steps</td>\n",
              "      <td>necessary</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>xxmaj</td>\n",
              "      <td>by</td>\n",
              "      <td>doing</td>\n",
              "      <td>this</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>the</td>\n",
              "      <td>data</td>\n",
              "      <td>block</td>\n",
              "      <td>xxup</td>\n",
              "      <td>api</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>a</td>\n",
              "      <td>language</td>\n",
              "      <td>model</td>\n",
              "      <td>and</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Just run:\n",
        "bs,seq_len = 6,5\n",
        "d_tokens = np.array([tokens[i*15+seq_len:i*15+2*seq_len] for i in range(bs)])\n",
        "df = pd.DataFrame(d_tokens)\n",
        "display(HTML(df.to_html(index=False,header=None)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "A8SHFBYDClx0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "ed85bf60-9f02-4442-f3d6-822445480bed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>over</td>\n",
              "      <td>the</td>\n",
              "      <td>example</td>\n",
              "      <td>of</td>\n",
              "      <td>classifying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>under</td>\n",
              "      <td>the</td>\n",
              "      <td>surface</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>convert</td>\n",
              "      <td>text</td>\n",
              "      <td>into</td>\n",
              "      <td>numbers</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>we</td>\n",
              "      <td>'ll</td>\n",
              "      <td>have</td>\n",
              "      <td>another</td>\n",
              "      <td>example</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>.</td>\n",
              "      <td>\\n</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>then</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>it</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>while</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Just run:\n",
        "bs,seq_len = 6,5\n",
        "d_tokens = np.array([tokens[i*15+10:i*15+15] for i in range(bs)])\n",
        "df = pd.DataFrame(d_tokens)\n",
        "display(HTML(df.to_html(index=False,header=None)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nums200 = toks200.map(num)\n",
        "type(nums200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "CdurxCEpj5qY",
        "outputId": "e6a9b7d8-1b62-448c-aa3b-1966ec08dcd6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fastcore.foundation.L"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>fastcore.foundation.L</b><br/>def __call__(cls, x=None, *args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/fastcore/foundation.py</a>Behaves like a list of `items` but can also index with list of indices or masks</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 101);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(nums200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY0HKdzTkAJl",
        "outputId": "d9ac464f-b2ce-4b24-f604-17dc036e91d0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nums200[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KbERXHFkCdX",
        "outputId": "fca8adb3-022c-4b95-f25f-3bafa176cb7d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorText([   2,   18,   77,   66,    0,   28,    9,   26,   10,  276,   17,   77,   13,  556,  335,  182,   12,   17,   16,    9,  682,   14,    9,    0,   14,    8, 1255,   12,    8,    0,   11,\n",
              "               8,  110,   10,   18,   25,    0,   15,  132,    9,   26,   91,   19,   25,  199,   48,    9,  170,  163,   61,  759,    9,  115,   28,    8, 1256, 1556,   91,   18, 1557,    8, 1256,\n",
              "             192,  123,   29,   59,    8, 1256,  192,   16, 1035,   15,    8,    0,   10,   18,   65,  179,    8, 1256,  192,   16,   83,    0,   11,   27,    8,   75,   18,  205,    9,  463,   45,\n",
              "               9,  307,   10,   18,  388,  556,   91,   17,   25,  206,   69,   20,   13,  556,  130,   11,    8,  110,   10,    9,   83,   95,  156,  683,    0,   89,  117,   11,    8,  107,   10,\n",
              "               9,  684,    0,   14,    9,   26,   16,    9,  298,  877,   11,    8,   89,   12,   85,  506,   70,  878,  507,    0,  117,  168,   19, 1558, 1559,   11,    8,   17,   25,   54,    8,\n",
              "            1255,  508,   66, 1257,  509,   12,   47,   12,    9,  509,   68,  193,    0,  685,   64,    8,    0,   76,   36,  193,   15,  101,   19,   15,  411,   94,   78,    9,  298,  877,   41,\n",
              "              11,   27,    8,    9,  103,  140,   56,    9,   26,   16,    9,  336,  118,  464,  115,   11,    8,   17, 1258,   89,   14,   66,   14,    9,  337,  760,   23,  128,   11,   27,    8,\n",
              "             110,   10,    9,   72,  140,    9,   26,   16,  308,   16,   14,  879,    8,    0,   10,   61,  510,   90,  465,   20,   19,    0,   28,   21,   10,   18,  207,   13,  880,   14,  192,\n",
              "              58,   14,  208,   11,   27,    8,  761,   10,  511,  370,  511,   76,   67,   31,  101,   19,   42,  338,   21,   17,   16,   13,  214, 1560,   26,   11,    8,  110,   10,   36,   86,\n",
              "             132,   19,   15,   38,   66, 1259,   45,    9,  309,  606,  158,   11,   27,    8,   21,  466,   47,   11])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nums200[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67gUFA48kMiE",
        "outputId": "e81aa289-1425-456b-8343-90bc620a5c4c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([297])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nums200[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXT9EJU3kO6U",
        "outputId": "424a30a4-4127-47c7-af70-633b9cb7694a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorText([   2,    8,  686, 1036,   10,   61,   41,    0,   58,   13, 1561,    0,   10,   41,    0,   48,   52,    0,  224,   11,   27,    8,    9,    8,    0,    8,   21,    8,    0,    8,  607,\n",
              "              37,    0,    8,    0,   35,   16,   13,  299,   14,   13,    0,    0,   28,  881,  882,   11,    8,    9,  128,  389, 1037,   41,  150,  267,   12,    9,  115,   28,    9,  116,  209,\n",
              "              16,  150,    0,   10,   51,   23,   68,   13,  687,    0, 1562,  225,   28,   13,  608,    0,   11,    8,   20,  249,   92,   14,    9,  115,   23, 1563,   24,   69,   16,  150, 1564,\n",
              "              10,  435,   28,   42,   43,  121, 1565,  883,   11,    8,   29,    9,   26,   16,   90,  114,  161,   48,  141, 1566,    0,    0,   37,   20,   52,    0, 1567,   35,   12,   42, 1568,\n",
              "               0,   10,    0,  884,   11,   27,    8,    9,  182,   16, 1569,   28,    9,  116,  209,   11,    8, 1570,    8,    0,   16,    9,  230,   14,    9,  238,   33,   50,  104,   13,  150,\n",
              "             556,  323,   20,  111,   11,    8,  151,  226,   28,   13,  339,    8,    0,    8,    0,   33,   52, 1260,   24,    0, 1038,   11,   27,    8,  153,   47,   19,   16,   13,  150, 1039,\n",
              "             609,  881,  688,   10,   29,    9, 1261,   16,  110,  308,    0,   12,   28,   19,  412,    0,    9,   26,   53,  122,   13,  390,    0,   24,    0,   11,   27,  108,  108,   58,   14,\n",
              "               5,  188,  108])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nums200[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO7AcWI-kQ6h",
        "outputId": "de5dc961-63a1-454a-ae02-faf9dac166a6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([220])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dl = LMDataLoader(nums200)\n",
        "type(dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "H2tJP0zWkGBD",
        "outputId": "142208a1-b286-4369-95ff-99ddbc676158"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fastai.text.data.LMDataLoader"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>fastai.text.data.LMDataLoader</b><br/>def __init__(dataset, lens=None, cache=2, bs=64, seq_len=72, num_workers=0, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/fastai/text/data.py</a>A `DataLoader` suitable for language modeling</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 72);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = first(dl)\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALk2WypukLJl",
        "outputId": "32dfb5b6-6f13-420e-c35c-d129d9a01e62"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 72]), torch.Size([64, 72]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(num.vocab[o] for o in x[0][:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Mm2ApBSZkd0l",
        "outputId": "ca971879-2183-464a-f105-9c16baa43cf3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxbos i had some xxunk for the movie , since it had a nice star cast and it is the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(num.vocab[o] for o in y[0][:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fr7_WhcgkonE",
        "outputId": "f0729120-64af-441f-bcf5-1a60f4a01110"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i had some xxunk for the movie , since it had a nice star cast and it is the return'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vshdfqnqClx1"
      },
      "source": [
        "## Training a Text Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpgFXRYLClx1"
      },
      "source": [
        "### Language Model Using DataBlock"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n",
        "dls_lm = DataBlock(\n",
        "    blocks=TextBlock.from_folder(path, is_lm=True),\n",
        "    get_items=get_imdb,\n",
        "    splitter=RandomSplitter(0.1)\n",
        ").dataloaders(path, path=path, bs=128, seq_len=80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "qfG3149zwO51",
        "outputId": "604b6191-f992-4401-a379-ebf4785f2c41"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(dls_lm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "S3YDuncMzsiJ",
        "outputId": "c29610ae-bb19-4be0-f743-6b9b12e51bc1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fastai.data.core.DataLoaders"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>fastai.data.core.DataLoaders</b><br/>def __init__(*loaders, path: str | Path=&#x27;.&#x27;, device=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/fastai/data/core.py</a>Basic wrapper around several `DataLoader`s.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 188);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dls_lm.show_batch(max_n=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "h9X-j8NrzRi-",
        "outputId": "6006d288-b165-438c-e35e-f5a4e59bb5a9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos i was never in the past interested in this play although love xxmaj shakespeare and have seen most of his plays now and enthusiastically studied some at school . xxmaj something about this story and all the fuss about it seemed to put me off . i never bothered to try to see xxmaj hamlet until fairly recently deciding i should at least try to watch it and i borrowed the xxmaj olivier version from the library . xxmaj</td>\n",
              "      <td>i was never in the past interested in this play although love xxmaj shakespeare and have seen most of his plays now and enthusiastically studied some at school . xxmaj something about this story and all the fuss about it seemed to put me off . i never bothered to try to see xxmaj hamlet until fairly recently deciding i should at least try to watch it and i borrowed the xxmaj olivier version from the library . xxmaj well</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\" life \" then the pro - capital punishment lobby would not have a leg to stand on . xxmaj but it does n't . xxmaj and so they do . \\n\\n xxmaj there were times when xxmaj aileen came across as likable . xxmaj genuinely likable . xxmaj and one could fully understand why the film maker felt a rapport with his subject . xxmaj when she was lucid she made sense . xxmaj she knew she had been</td>\n",
              "      <td>life \" then the pro - capital punishment lobby would not have a leg to stand on . xxmaj but it does n't . xxmaj and so they do . \\n\\n xxmaj there were times when xxmaj aileen came across as likable . xxmaj genuinely likable . xxmaj and one could fully understand why the film maker felt a rapport with his subject . xxmaj when she was lucid she made sense . xxmaj she knew she had been stitched</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's explore an actual minibatch comprising input IDs."
      ],
      "metadata": {
        "id": "d7-rf22EbZeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls_lm[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaIG1S7Uza-T",
        "outputId": "6dd3b578-705c-4e7b-820f-c2c7b33e978e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.text.data.LMDataLoader at 0x7d64bab1f850>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(iter(dls_lm[0]))\n",
        "x_batch.shape, y_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLjsfOxmzvnb",
        "outputId": "a3726d66-baf1-4a43-d9a1-d08c92d35b7a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 80]), torch.Size([128, 80]))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RqL6OjYz7Cb",
        "outputId": "7401a9d0-67c8-4334-a6c7-b57353ec37ca"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMTensorText([    2,     8,   129,    13,  6014,  1823,   564,    11,    19,    85,   527,    20,    30,    11,   263,    70,    52,    94,     9,   849,   420,    10,     8,    44,    14,     9,\n",
              "               1563,   404,    18,     9,    30,    16,    69,     9, 28936,    11,    50,    87,  1855,    41,     8,  1576,  3102,    11,    16,  6210,    37,   195,    34,    48,     8,  3282,\n",
              "                318,    13,  6014,     0,    37,    49,  1635,   136,    13,   601,  1823,   312,  4840,   467,   457,  1810,    46,   302,    34,    10,     8,    40,   492,    52,  6735,    21,\n",
              "                 40,   241], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_batch[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBYxjD0fz9ew",
        "outputId": "34566cda-3904-409c-8d6f-32fccc573a12"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorText([    8,   129,    13,  6014,  1823,   564,    11,    19,    85,   527,    20,    30,    11,   263,    70,    52,    94,     9,   849,   420,    10,     8,    44,    14,     9,  1563,   404,\n",
              "               18,     9,    30,    16,    69,     9, 28936,    11,    50,    87,  1855,    41,     8,  1576,  3102,    11,    16,  6210,    37,   195,    34,    48,     8,  3282,   318,    13,  6014,\n",
              "                0,    37,    49,  1635,   136,    13,   601,  1823,   312,  4840,   467,   457,  1810,    46,   302,    34,    10,     8,    40,   492,    52,  6735,    21,    40,   241,     0],\n",
              "           device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(dls_lm.vocab), len(dls_lm.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPruFhxN2xFy",
        "outputId": "17778333-452f-46a8-c304-aaa8fccca11e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 60008)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dls_lm.vocab[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmulB9tT22nf",
        "outputId": "3cedbc26-ae79-410c-ef3d-abc5e2e10217"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxrep', 'xxwrep', 'xxup', 'xxmaj', 'the', '.', ',', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this', 'that', '\"', \"'s\", '-', 'was', '\\n\\n', 'as', 'with', 'for']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uz5xs0WClx2"
      },
      "source": [
        "### Fine-Tuning the Language Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = language_model_learner(dls_lm, AWD_LSTM, drop_mult=0.3, metrics=[accuracy, Perplexity()]).to_fp16()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "PNdSHNCI34nq",
        "outputId": "0a87c60d-fffe-493a-d19e-d46576b47a60"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [105070592/105067061 00:03&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "pNzjrawkClx2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ca15c6f5-6d3c-4741-f510-1a73aa7b2582"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fastai.text.learner.LMLearner"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>fastai.text.learner.LMLearner</b><br/>def __call__(event_name)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/fastai/text/learner.py</a>Add functionality to `TextLearner` when dealing with a language model</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 190);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "type(learn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1, 2e-2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "5cue3hUr5TUA",
        "outputId": "a57cba82-77b0-4f2e-816c-9b5a3ecdf196"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.004985</td>\n",
              "      <td>3.907380</td>\n",
              "      <td>0.300211</td>\n",
              "      <td>49.768383</td>\n",
              "      <td>13:20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkesJRJ0Clx2"
      },
      "source": [
        "### Saving and Loading Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.save('1epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lu7iD438egQ",
        "outputId": "fcb49d7b-9f6c-4754-af9d-5238e85b9954"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/imdb/models/1epoch.pth')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = learn.load('1epoch')"
      ],
      "metadata": {
        "id": "ggZqLuZ28ihL"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(10, 2e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "mxU2Wx8E8mKu",
        "outputId": "9d75c1b4-4f3f-4922-f828-85acf6610d29"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.751968</td>\n",
              "      <td>3.769070</td>\n",
              "      <td>0.315992</td>\n",
              "      <td>43.339737</td>\n",
              "      <td>13:49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.703485</td>\n",
              "      <td>3.708263</td>\n",
              "      <td>0.323104</td>\n",
              "      <td>40.782921</td>\n",
              "      <td>13:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.646224</td>\n",
              "      <td>3.659706</td>\n",
              "      <td>0.328522</td>\n",
              "      <td>38.849907</td>\n",
              "      <td>13:50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.539139</td>\n",
              "      <td>3.624274</td>\n",
              "      <td>0.332636</td>\n",
              "      <td>37.497475</td>\n",
              "      <td>13:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.497658</td>\n",
              "      <td>3.602425</td>\n",
              "      <td>0.335232</td>\n",
              "      <td>36.687096</td>\n",
              "      <td>13:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.430049</td>\n",
              "      <td>3.587172</td>\n",
              "      <td>0.337779</td>\n",
              "      <td>36.131752</td>\n",
              "      <td>13:33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.350357</td>\n",
              "      <td>3.578308</td>\n",
              "      <td>0.339165</td>\n",
              "      <td>35.812908</td>\n",
              "      <td>13:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.304235</td>\n",
              "      <td>3.574070</td>\n",
              "      <td>0.340153</td>\n",
              "      <td>35.661457</td>\n",
              "      <td>14:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3.257838</td>\n",
              "      <td>3.576935</td>\n",
              "      <td>0.340398</td>\n",
              "      <td>35.763752</td>\n",
              "      <td>14:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>3.212648</td>\n",
              "      <td>3.581804</td>\n",
              "      <td>0.340225</td>\n",
              "      <td>35.938301</td>\n",
              "      <td>13:56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.save_encoder('finetuned')"
      ],
      "metadata": {
        "id": "yhseCGzIcVZe"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjDXEfBuClx3"
      },
      "source": [
        "### Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = \"I liked this movie because\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fWCHkI8Nc0-n",
        "outputId": "03b86d97-8ea8-4f7b-e675-d8cb6e828ad4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "relCa7OmdZiN",
        "outputId": "0d7d0e23-5297-455b-b106-4638309e6fae"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"i liked this movie because it dealt with real issues which were very important . It was good for the movie 's part and for that , i think the performances by Gary Cooper , Helen Hunt , and\",\n",
              " \"i liked this movie because it was a good comedy . The two lead actors are really good . It could have been a real comedy . If you can , if you 're a fan of the Comedy Central\"]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\".join(preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YpWOAoQdc1Y",
        "outputId": "ba6b5240-b967-4d66-db6b-1beed27529f5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i liked this movie because it dealt with real issues which were very important . It was good for the movie 's part and for that , i think the performances by Gary Cooper , Helen Hunt , and\n",
            "i liked this movie because it was a good comedy . The two lead actors are really good . It could have been a real comedy . If you can , if you 're a fan of the Comedy Central\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaNkxNQFClx4"
      },
      "source": [
        "### Creating the Classifier DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMwdN_EKClx4"
      },
      "outputs": [],
      "source": [
        "dls_clas = DataBlock(\n",
        "    blocks=(TextBlock.from_folder(path, vocab=dls_lm.vocab),CategoryBlock),\n",
        "    get_y = parent_label,\n",
        "    get_items=partial(get_text_files, folders=['train', 'test']),\n",
        "    splitter=GrandparentSplitter(valid_name='test')\n",
        ").dataloaders(path, path=path, bs=128, seq_len=72)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-ZRF5a0Clx5"
      },
      "outputs": [],
      "source": [
        "dls_clas.show_batch(max_n=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M019Sc_hClx5"
      },
      "outputs": [],
      "source": [
        "nums_samp = toks200[:10].map(num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4azSrHq0Clx5"
      },
      "outputs": [],
      "source": [
        "nums_samp.map(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u7-wxVEClx5"
      },
      "outputs": [],
      "source": [
        "learn = text_classifier_learner(dls_clas, AWD_LSTM, drop_mult=0.5,\n",
        "                                metrics=accuracy).to_fp16()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6KkG2uFClx5"
      },
      "outputs": [],
      "source": [
        "learn = learn.load_encoder('finetuned')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEpAxgPEClx6"
      },
      "source": [
        "### Fine-Tuning the Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFPeuSr5Clx6"
      },
      "outputs": [],
      "source": [
        "learn.fit_one_cycle(1, 2e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aIgFLxIClx6"
      },
      "outputs": [],
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZSi1qsbClx7"
      },
      "outputs": [],
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRed8LhXClx7"
      },
      "outputs": [],
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ex-iE5uClx7"
      },
      "source": [
        "## Disinformation and Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoEVv01RClx7"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXjpCAfKClx7"
      },
      "source": [
        "## Questionnaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9x6D_JoClx8"
      },
      "source": [
        "1. What is \"self-supervised learning\"?\n",
        "1. What is a \"language model\"?\n",
        "1. Why is a language model considered self-supervised?\n",
        "1. What are self-supervised models usually used for?\n",
        "1. Why do we fine-tune language models?\n",
        "1. What are the three steps to create a state-of-the-art text classifier?\n",
        "1. How do the 50,000 unlabeled movie reviews help us create a better text classifier for the IMDb dataset?\n",
        "1. What are the three steps to prepare your data for a language model?\n",
        "1. What is \"tokenization\"? Why do we need it?\n",
        "1. Name three different approaches to tokenization.\n",
        "1. What is `xxbos`?\n",
        "1. List four rules that fastai applies to text during tokenization.\n",
        "1. Why are repeated characters replaced with a token showing the number of repetitions and the character that's repeated?\n",
        "1. What is \"numericalization\"?\n",
        "1. Why might there be words that are replaced with the \"unknown word\" token?\n",
        "1. With a batch size of 64, the first row of the tensor representing the first batch contains the first 64 tokens for the dataset. What does the second row of that tensor contain? What does the first row of the second batch contain? (Careful—students often get this one wrong! Be sure to check your answer on the book's website.)\n",
        "1. Why do we need padding for text classification? Why don't we need it for language modeling?\n",
        "1. What does an embedding matrix for NLP contain? What is its shape?\n",
        "1. What is \"perplexity\"?\n",
        "1. Why do we have to pass the vocabulary of the language model to the classifier data block?\n",
        "1. What is \"gradual unfreezing\"?\n",
        "1. Why is text generation always likely to be ahead of automatic identification of machine-generated texts?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZtkqAgBClx9"
      },
      "source": [
        "### Further Research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giJKBEj_Clx9"
      },
      "source": [
        "1. See what you can learn about language models and disinformation. What are the best language models today? Take a look at some of their outputs. Do you find them convincing? How could a bad actor best use such a model to create conflict and uncertainty?\n",
        "1. Given the limitation that models are unlikely to be able to consistently recognize machine-generated texts, what other approaches may be needed to handle large-scale disinformation campaigns that leverage deep learning?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEJimuchClx9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1ZtkqAgBClx9"
      ],
      "provenance": [],
      "gpuType": "V100"
    },
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}