{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ukp0Mwlja7UW",
        "outputId": "e1aa56e0-e422-4ac6-e8e5-0618ce29d25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "![ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YbnpMmxFa7UX"
      },
      "outputs": [],
      "source": [
        "from fastbook import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dunXy_Na7UX"
      },
      "source": [
        "# A Language Model from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eFfJx8va7UY"
      },
      "source": [
        "## The Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.text.all import *"
      ],
      "metadata": {
        "id": "ZVihCM5Lr1lk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URLs.HUMAN_NUMBERS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3pvxuyX2r58k",
        "outputId": "314b54ce-45ca-4375-84b9-357c630a3883"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://s3.amazonaws.com/fast-ai-sample/human_numbers.tgz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.HUMAN_NUMBERS)\n",
        "path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "b31f6zyZr8t4",
        "outputId": "6b1d5bbc-0b51-41e1-d67f-d41759f1f2ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='32768' class='' max='30252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      108.32% [32768/30252 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/human_numbers')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Path.BASE_PATH = path\n",
        "path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_o3ShxTsCI5",
        "outputId": "070c7626-c27b-444c-fbb6-8af5bf68bbdb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('.')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaBf9k8nsFw8",
        "outputId": "40f72b4d-8a81-491b-f2df-b49204a025be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('valid.txt'),Path('train.txt')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = L()\n",
        "with open(path/'train.txt') as f:\n",
        "    lines += L(*f.readlines())\n",
        "with open(path/'valid.txt') as f:\n",
        "    lines += L(*f.readlines())\n",
        "lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW-td7UEsIvl",
        "outputId": "66c538fe-7c15-484f-e6c5-e9c37903f844"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#9998) ['one \\n','two \\n','three \\n','four \\n','five \\n','six \\n','seven \\n','eight \\n','nine \\n','ten \\n'...]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines[-10:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQCto1lMsenn",
        "outputId": "16eb8d47-f577-4da8-d192-834073ba8397"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) ['nine thousand nine hundred ninety \\n','nine thousand nine hundred ninety one \\n','nine thousand nine hundred ninety two \\n','nine thousand nine hundred ninety three \\n','nine thousand nine hundred ninety four \\n','nine thousand nine hundred ninety five \\n','nine thousand nine hundred ninety six \\n','nine thousand nine hundred ninety seven \\n','nine thousand nine hundred ninety eight \\n','nine thousand nine hundred ninety nine \\n']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" . \".join([l.strip() for l in lines])\n",
        "text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SyE9rbK7smfN",
        "outputId": "677101ff-9328-4058-e7f9-09782657d210"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'one . two . three . four . five . six . seven . eight . nine . ten . eleven . twelve . thirteen . fo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = text.split(\" \")\n",
        "tokens[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTR3-Qy7s24K",
        "outputId": "779c211c-d97c-4369-fa9b-3fec218a71b2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W2twlRHs8fR",
        "outputId": "801ad0f5-3145-4faa-e36f-232ad9edfb15"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63095"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[-10:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1CZ6RvqtA5X",
        "outputId": "a39dc2b4-3dd4-4389-b9d5-00bf9683f394"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hundred',\n",
              " 'ninety',\n",
              " 'eight',\n",
              " '.',\n",
              " 'nine',\n",
              " 'thousand',\n",
              " 'nine',\n",
              " 'hundred',\n",
              " 'ninety',\n",
              " 'nine']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = L(*tokens).unique()\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISvkp7rjtEAk",
        "outputId": "c09d41ec-80f4-44f8-b571-8ae57cf433ae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "nums = L(word2idx[t] for t in tokens)\n",
        "nums"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXuwOJ-utNRS",
        "outputId": "95e27672-15d1-454c-b6f5-b64a64233bd9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#63095) [0,1,2,1,3,1,4,1,5,1...]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The last index is `63094`."
      ],
      "metadata": {
        "id": "pP6hbd0ZiosR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nqho_dWa7UZ"
      },
      "source": [
        "## Our First Language Model from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens) - 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTyQeG0tvbac",
        "outputId": "878e2cb5-d35b-4af2-c625-2d0e296e4bf8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63091"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range(0, len(tokens) - 4, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYmdUzeVvgqX",
        "outputId": "5780d4b1-c7c3-4538-b5e6-85fc20b9062b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 63091, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When `i` is `63091`, then `i + 3` is `63094`, which is the last index."
      ],
      "metadata": {
        "id": "TvAkL-_ji4dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L((tokens[i:i + 3], tokens[i + 3]) for i in range(0, len(tokens) - 4, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95xizVLbv099",
        "outputId": "32b1b3b9-9bf7-4dbb-c637-8a6d2730d79f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(['one', '.', 'two'], '.'),(['.', 'three', '.'], 'four'),(['four', '.', 'five'], '.'),(['.', 'six', '.'], 'seven'),(['seven', '.', 'eight'], '.'),(['.', 'nine', '.'], 'ten'),(['ten', '.', 'eleven'], '.'),(['.', 'twelve', '.'], 'thirteen'),(['thirteen', '.', 'fourteen'], '.'),(['.', 'fifteen', '.'], 'sixteen')...]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The slice `i:i + 3` isn't inclusive of `i + 3`. (It contains tokens `i`, `i + 1` and `i + 2`.) So we're using sequences of every 3 tokens as our independent variable, and the next token as our dependent variable."
      ],
      "metadata": {
        "id": "g7-M2IOBja7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For comparison:\n",
        "print(tokens[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L3V1HUewAT1",
        "outputId": "06ab11e5-2465-47ed-9490-016f0efa7b67"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['one', '.', 'two', '.', 'three', '.', 'four', '.', 'five', '.', 'six', '.', 'seven', '.', 'eight', '.', 'nine', '.', 'ten', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seqs = L((tensor(nums[i:i + 3]), nums[i + 3]) for i in range(0, len(nums) - 4, 3))\n",
        "seqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg0d8UDpwJL3",
        "outputId": "13d18db5-523d-4c65-9970-7f0e5caec5e0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The above can be treated as a PyTorch `Dataset`, because it has a length, and supports indexing."
      ],
      "metadata": {
        "id": "jjDDCJG0l8OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 32\n",
        "cut = int(len(seqs) * 0.8)\n",
        "cut"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl0NkigEwnpL",
        "outputId": "256a4828-f62f-4b67-b1fd-27b37de8454a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16824"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dls = DataLoaders.from_dsets(seqs[:cut], seqs[cut:], bs=bs, shuffle=False)\n",
        "dls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfOSZdjGwxCi",
        "outputId": "b6c45178-d8d2-4c50-d4df-dbbba0019bbe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.data.core.DataLoaders at 0x7b3afe294d90>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dls.train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mAu5l4Hw5sj",
        "outputId": "398c6e40-326c-4036-c31f-444ee67a3860"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fastai.data.core.TfmdDL at 0x7b3c02429450>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(dls.train))\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uflDCBC2xbBD",
        "outputId": "5913255f-66cb-4662-f98b-2f429cf4cd7a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZNKm79-xgMx",
        "outputId": "0f0e001c-cef0-4221-b48e-a907312b2647"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2],\n",
              "        [1, 3, 1],\n",
              "        [4, 1, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The second row is a continuation of the sequence (after the end of the first row). This data prep isn't suitable for a stateful RNN."
      ],
      "metadata": {
        "id": "slioVxGdVfGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdzlhq_PxnFK",
        "outputId": "6f897ede-4cb3-4ef3-9888-25946c83f07c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** We don't have to one-hot encode the labels."
      ],
      "metadata": {
        "id": "w0kBwFtFlw16"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM9RzuQNa7Ua"
      },
      "source": [
        "### Our Language Model in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the forward pass works for `nn.Embedding`:"
      ],
      "metadata": {
        "id": "tP_wCZoPYURI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i_h = nn.Embedding(len(vocab), 64)\n",
        "i_h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL8-q6oMdKYw",
        "outputId": "a8c1bb46-1eee-41bd-be32-262f55773ca5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(30, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we pass in a batch of full sequences:"
      ],
      "metadata": {
        "id": "wKl8-_n8YcbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    h = i_h(x)\n",
        "h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWlPBa8hdScV",
        "outputId": "6617408e-6681-42e5-aac5-80ab76513a0e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we pass in a batch of only the first token:"
      ],
      "metadata": {
        "id": "RsU579SVYj2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    h = i_h(x[:, 0])\n",
        "h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0URiCppd1EJ",
        "outputId": "8714c0ff-cc94-4452-8596-88d47d051840"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel1(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz) # Classification layer, a.k.a. 'head'.\n",
        "\n",
        "    def forward(self, x): # (bs, 3)\n",
        "        h = 0 + self.i_h(x[:, 0]) # (bs, n_hidden)\n",
        "        h = F.relu(self.h_h(h)) # (bs, n_hidden)\n",
        "        h = h + self.i_h(x[:, 1]) # (bs, n_hidden)\n",
        "        h = F.relu(self.h_h(h)) # (bs, n_hidden)\n",
        "        h = h + self.i_h(x[:, 2]) # (bs, n_hidden)\n",
        "        h = F.relu(self.h_h(h)) # (bs, n_hidden)\n",
        "        return self.h_o(h) # (bs, vocab_sz)"
      ],
      "metadata": {
        "id": "G0S-Zl5Md8c9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "1. This is a sequence-to-vector RNN. It produces an output only for the last token in the sequence, not for every token in the sequence.\n",
        "2. Each token is represented as a vector of length `n_hidden`. `n_hidden` can also be thought of as the number of channels. It should be treated as a hyperparameter.\n",
        "3. This network only works for sequences of length `3`. (We shall see how to change this shortly.)\n",
        "4. The slices `x[:, 0]`, `x[:, 1]` and `x[:, 2]` indicate that we're processing a batch at a time (like all neural networks), but only one token at a time.\n",
        "5. The `nn.Linear` layer `self.h_h` is re-used at each time step, because this linear layer is describing how the hidden state changes (gets updated) as we go from one token to the next. So this layer is expected to learn the weights to perform this computation (for all sorts of inputs).\n",
        "6. Just like in the case of `ResBlock`, the addition happens after the ReLU. (In this case, the input embedding vector of the next token is added to the ReLU activation of the current token. For this addition to work, the shapes of the two tensors must be the same. In other words, the `self.h_h` layer cannot change the number of channels, i.e., the length of the embedding vector.)\n",
        "7. PyTorch's `nn.RNNCell` class is (almost, but not quite) equivalent to applying `self.h_h` and the non-linearity. (It doesn't have the for loop built in! We have to write it ourselves.) See the math of the actual operation here: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n",
        "8. And PyTorch's <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\" target=\"_blank\">nn.RNN</a> class is (almost) equivalent to stacking multiple `nn.RNNCell` layers. Only `nn.RNN` provides the `batch_first=True`, `dropout` and `bidirectional` options. If we use `nn.RNNCell`, we have to apply these manually ourselves. (The for loop is built in. We don't have to write it ourselves.)\n",
        "9. From the equations in the documentations of `nn.RNNCell` and `nn.RNN`, we see that the embedding of the current token is not directly added to the previous activation. Rather, it is passed through a linear layer first. The ReLU is applied after adding the outputs of the two linear layers (one for processing the input embeddings and one for processing the hidden state). This also means that the number of embedding dimensions CAN be changed by an RNN layer (because the two linear layers inside it have the same number of output units - the `hidden_size` argument, making addition of the outputs of the two linear layers possible).\n",
        "10. The input shape of `nn.RNN` is $(N, L, H_{in})$ when `batch_first=True`. In other words, it doesn't accept one token at a time. It only accepts a full sequence (of length $L$) - typically a batch of these. Its output shape is $(N, L, D∗H_{out})$, where $D=2$ if `bidirectional=True`, otherwise $1$. From the output shape, we see that it's a sequence-to-sequence RNN. But we can easily make it sequence-to-vector by ignoring the outputs of all but the last time step.\n",
        "11. In a simple RNN cell, the output (at any time step) and the hidden state (at any time step) are the same thing. In an LSTM / GRU cell, they are different."
      ],
      "metadata": {
        "id": "AXxE6Tf5onZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNNStateless(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, nonlinearity='tanh', return_sequences=False):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Linear(input_size, hidden_size)\n",
        "        self.h_h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.nonlinearity = nonlinearity\n",
        "        self.return_sequences = return_sequences\n",
        "\n",
        "    def forward(self, x): # (bs, seq_len, input_size)\n",
        "        bs, seq_len, input_size = x.shape\n",
        "        h = torch.zeros((bs, self.hidden_size)) # (bs, hidden_size)\n",
        "        all_hidden_states = []\n",
        "        for i in range(seq_len):\n",
        "            i_h = self.i_h(x[:, i]) # (bs, hidden_size)\n",
        "            h_h = self.h_h(h) # (bs, hidden_size)\n",
        "            if self.nonlinearity == 'tanh':\n",
        "                h = torch.tanh(i_h + h_h) # (bs, hidden_size)\n",
        "            else:\n",
        "                h = torch.relu(i_h + h_h) # (bs, hidden_size)\n",
        "            all_hidden_states.append(h)\n",
        "        if self.return_sequences:\n",
        "            return torch.stack(all_hidden_states, dim=1) # (bs, seq_len, hidden_size)\n",
        "        else:\n",
        "            return all_hidden_states[-1] # (bs, hidden_size)"
      ],
      "metadata": {
        "id": "R0qMKGqWfMNt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel1Alt(nn.Module):\n",
        "    def __init__(self, vocab_size, input_emb_size, hidden_size, nonlinearity='tanh', return_sequences=False):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, input_emb_size)\n",
        "        self.rnn = SimpleRNNStateless(input_emb_size, hidden_size, nonlinearity=nonlinearity, return_sequences=return_sequences)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x): # (bs, seq_len)\n",
        "        input_emb = self.emb(x) # (bs, seq_len, input_emb_size)\n",
        "        y = self.rnn(input_emb) # (bs, seq_len, hidden_size) if return_sequences == True else (bs, hidden_size)\n",
        "        return self.linear(y) # (bs, seq_len, vocab_size) if return_sequences == True else (bs, vocab_size)"
      ],
      "metadata": {
        "id": "mSj2m-bEifyM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel1Alt2(nn.Module):\n",
        "    def __init__(self, vocab_size, input_emb_size, hidden_size, nonlinearity='tanh', return_sequences=False):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, input_emb_size)\n",
        "        self.rnn = nn.RNNCell(input_emb_size, hidden_size, nonlinearity=nonlinearity)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.return_sequences = return_sequences\n",
        "\n",
        "    def forward(self, x): # (bs, seq_len)\n",
        "        input_emb = self.emb(x) # (bs, seq_len, input_emb_size)\n",
        "        bs, seq_len = x.shape\n",
        "        h = torch.zeros((bs, self.hidden_size)) # (bs, hidden_size)\n",
        "        all_hidden_states = []\n",
        "        for i in range(seq_len):\n",
        "            h = self.rnn(input_emb[:, i], h) # (bs, hidden_size)\n",
        "            all_hidden_states.append(h)\n",
        "        if self.return_sequences:\n",
        "            y = torch.stack(all_hidden_states, dim=1) # (bs, seq_len, hidden_size)\n",
        "        else:\n",
        "            y = all_hidden_states[-1] # (bs, hidden_size)\n",
        "        return self.linear(y) # (bs, seq_len, vocab_size) if return_sequences == True else (bs, vocab_size)"
      ],
      "metadata": {
        "id": "1FWVP4selgVa"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel1Alt3(nn.Module):\n",
        "    def __init__(self, vocab_size, input_emb_size, hidden_size, nonlinearity='tanh', return_sequences=False):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, input_emb_size)\n",
        "        self.rnn = nn.RNN(input_emb_size, hidden_size, num_layers=1, nonlinearity=nonlinearity, batch_first=True, dropout=0.0, bidirectional=False)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.return_sequences = return_sequences\n",
        "\n",
        "    def forward(self, x): # (bs, seq_len)\n",
        "        input_emb = self.emb(x) # (bs, seq_len, input_emb_size)\n",
        "        bs = x.shape[0]\n",
        "        h = torch.zeros((1, bs, self.hidden_size))\n",
        "        # h is the initial hidden state with shape (D * 1, bs, hidden_size); 1 is the number of layers.\n",
        "        # D = 2 if bidirectional == True else 1.\n",
        "        y, h = self.rnn(input_emb, h) # (bs, seq_len, hidden_size) is the shape of y.\n",
        "        # h is the last hidden state with shape (D * 1, bs, hidden_size); 1 is the number of layers.\n",
        "        # D = 2 if bidirectional == True else 1.\n",
        "        if not self.return_sequences:\n",
        "            y = y[:, -1] # (bs, hidden_size) if return_sequences == False\n",
        "        return self.linear(y) # (bs, seq_len, vocab_size) if return_sequences == True else (bs, vocab_size)"
      ],
      "metadata": {
        "id": "kKYxpBhcoB9C"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LMModel1(len(vocab), 64)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrMu0l-04Dyx",
        "outputId": "bd1ab41d-cf20-4d47-810a-c5208e063c84"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel1(\n",
              "  (i_h): Embedding(30, 64)\n",
              "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (h_o): Linear(in_features=64, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    output = model(x)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PDJ1-vI4JJM",
        "outputId": "3be80da5-99cf-4460-944a-39e3fa4e7238"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt = LMModel1Alt(vocab_size=len(vocab), input_emb_size=64, hidden_size=128, nonlinearity='tanh', return_sequences=False)\n",
        "model_alt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JadTN5HdDqsB",
        "outputId": "4fdb2f15-174e-44f3-e843-7e8f22fc3947"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel1Alt(\n",
              "  (emb): Embedding(30, 64)\n",
              "  (rnn): SimpleRNNStateless(\n",
              "    (i_h): Linear(in_features=64, out_features=128, bias=True)\n",
              "    (h_h): Linear(in_features=128, out_features=128, bias=True)\n",
              "  )\n",
              "  (linear): Linear(in_features=128, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    output = model_alt(x)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS315sUSD6CT",
        "outputId": "7306487f-4d43-44fa-848f-958716d3286f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt2 = LMModel1Alt2(vocab_size=len(vocab), input_emb_size=64, hidden_size=128, nonlinearity='tanh', return_sequences=False)\n",
        "model_alt2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmYb_GCeL-nk",
        "outputId": "4b005998-90cc-470c-9573-c9a6f5c13e5c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel1Alt2(\n",
              "  (emb): Embedding(30, 64)\n",
              "  (rnn): RNNCell(64, 128)\n",
              "  (linear): Linear(in_features=128, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    output = model_alt2(x)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUwEHOAuMP6X",
        "outputId": "653e7d3f-2626-49c5-d638-3ea18ac19386"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt3 = LMModel1Alt3(vocab_size=len(vocab), input_emb_size=64, hidden_size=128, nonlinearity='tanh', return_sequences=False)\n",
        "model_alt3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swy_dZXYQ2Am",
        "outputId": "b0348a42-d54b-4ab8-d68e-54deeb35cafc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel1Alt3(\n",
              "  (emb): Embedding(30, 64)\n",
              "  (rnn): RNN(64, 128, batch_first=True)\n",
              "  (linear): Linear(in_features=128, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    output = model_alt3(x)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMoS2kvZRZm3",
        "outputId": "07fc925e-2495-4d80-cd3e-bdfca409daf7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, model, loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "ke47z6hv4VRG",
        "outputId": "70822b75-b985-43cc-c717-5f941844f40a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.398951</td>\n",
              "      <td>1.794102</td>\n",
              "      <td>0.487996</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.217450</td>\n",
              "      <td>1.848997</td>\n",
              "      <td>0.492512</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.295240</td>\n",
              "      <td>1.669092</td>\n",
              "      <td>0.502971</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.319708</td>\n",
              "      <td>1.543958</td>\n",
              "      <td>0.503209</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, model_alt, loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "-3eBqL5OEXWD",
        "outputId": "4d22f9d9-8091-4789-b259-f7630a27dd32"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.360079</td>\n",
              "      <td>1.751474</td>\n",
              "      <td>0.498455</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.214865</td>\n",
              "      <td>1.606199</td>\n",
              "      <td>0.504873</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.252462</td>\n",
              "      <td>1.504943</td>\n",
              "      <td>0.492750</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.317471</td>\n",
              "      <td>1.417318</td>\n",
              "      <td>0.506774</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Elman RNN is performing slightly better than Jeremy's RNN."
      ],
      "metadata": {
        "id": "86R5ElOYz6va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, model_alt2, loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "oaft3LiVMYFP",
        "outputId": "a14c6796-1cef-4eef-b953-370a92728bc0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.364671</td>\n",
              "      <td>1.764364</td>\n",
              "      <td>0.502258</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.205749</td>\n",
              "      <td>1.646668</td>\n",
              "      <td>0.505348</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.242550</td>\n",
              "      <td>1.547754</td>\n",
              "      <td>0.492988</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.327011</td>\n",
              "      <td>1.419009</td>\n",
              "      <td>0.506299</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, model_alt3, loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "Jp4kHjjxRijv",
        "outputId": "d0521695-5f95-4348-cb3d-ac17521aa526"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.345879</td>\n",
              "      <td>1.877276</td>\n",
              "      <td>0.503684</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.205580</td>\n",
              "      <td>1.647215</td>\n",
              "      <td>0.504873</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.254634</td>\n",
              "      <td>1.543316</td>\n",
              "      <td>0.492512</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.330067</td>\n",
              "      <td>1.418514</td>\n",
              "      <td>0.506774</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Let's simulate one iteration of the loop below:"
      ],
      "metadata": {
        "id": "LhWdUkVVf89w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n, counts = 0, torch.zeros(len(vocab))\n",
        "counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaHejU0T47jq",
        "outputId": "5e09af4a-8df7-4a1f-df69-5cea499199d4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(dls.valid))\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKmUyBdk4_pD",
        "outputId": "abfe901f-1ffa-446f-92ec-546afc358ce3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12cGBkZc5ELi",
        "outputId": "36149925-7194-48e5-aa2b-df2ee9af1afd"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n += y.shape[0]\n",
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jgPDxNE5Gib",
        "outputId": "b9e346ed-144c-452f-a963-bd76c4fa3b12"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(range_of(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4D29bBJ5MP0",
        "outputId": "da00f1f4-de2f-4404-a78a-5ba26906b5d8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range_of(vocab):\n",
        "    counts[i] += (y == i).long().sum()\n",
        "counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPqmJOKq5PFb",
        "outputId": "53c92cfe-2efb-4a0f-a640-f85bc0b6ce87"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4., 1., 1., 1., 0., 1., 1., 6., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 3., 1., 8.])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "n9Y-AtEmggbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n, counts = 0, torch.zeros(len(vocab))\n",
        "for x, y in dls.valid:\n",
        "    n += y.shape[0]\n",
        "    for i in range_of(vocab):\n",
        "        counts[i] += (y == i).long().sum()\n",
        "counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9oXH74V5XYt",
        "outputId": "d3ad9085-ddcb-438d-dd91-2e4f0f40031d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([106., 637., 159., 107., 106., 159., 108., 106., 464., 442.,   6.,   7.,   6.,   6.,   7.,   6.,   6.,   7.,   6.,   6.,  64.,  63.,  63.,  64.,  63.,  63.,  66.,  66., 600., 638.])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = torch.argmax(counts)\n",
        "idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czOsEi185rYJ",
        "outputId": "a90e174a-dece-44b5-e13b-0b4239f3de20"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(29)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab[idx.item()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RMtIp8H85uTd",
        "outputId": "7e8893b5-3127-4842-dbc5-bbb80007e856"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thousand'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts[idx].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct-9HBBu5wr9",
        "outputId": "5a43fd1f-8b70-4440-ea74-4df38ef27064"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "638.0"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeJ1Qwzz50Py",
        "outputId": "b272babb-771a-4042-83bd-1be4420c4a53"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4207"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts[idx].item() / n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyFZtR_m51V_",
        "outputId": "3aa2905c-70de-4162-ae19-6264cfec1eb2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15165200855716662"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVYvWCksa7Ua"
      },
      "source": [
        "### Our First Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel2(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = 0\n",
        "        for i in range(3):\n",
        "            h = h + self.i_h(x[:, i])\n",
        "            h = F.relu(self.h_h(h))\n",
        "        return self.h_o(h)"
      ],
      "metadata": {
        "id": "kqothIG1tP1f"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** If we had a situation where our batches had dynamic `seq_len`, then we could simply replace `range(3)` with `range(seq_len)` to make the above architecture work for ANY value of `seq_len`."
      ],
      "metadata": {
        "id": "l4BckIMQqBUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, LMModel2(len(vocab), 64), loss_func=F.cross_entropy, metrics=accuracy)\n",
        "learn.fit_one_cycle(4, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "KuDlY87zXP0l",
        "outputId": "9205cd65-6925-439d-91a9-7e0a5fb6a6cf"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.409812</td>\n",
              "      <td>2.016550</td>\n",
              "      <td>0.488234</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.241343</td>\n",
              "      <td>1.931480</td>\n",
              "      <td>0.494652</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.286902</td>\n",
              "      <td>1.713521</td>\n",
              "      <td>0.492750</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.315216</td>\n",
              "      <td>1.551980</td>\n",
              "      <td>0.505586</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FbnyvCDa7Ub"
      },
      "source": [
        "## Improving the RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA22Ck4ia7Ub"
      },
      "source": [
        "### Maintaining the State of an RNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel3(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(3):\n",
        "            self.h = self.h + self.i_h(x[:, i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "        out = self.h_o(self.h)\n",
        "        self.h = self.h.detach()\n",
        "        return out\n",
        "\n",
        "    def reset(self):\n",
        "        self.h = 0"
      ],
      "metadata": {
        "id": "zNTBPpGx-ZT2"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The `detach` method isn't in-place."
      ],
      "metadata": {
        "id": "ydvZZ13VaBlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNNStateful(nn.Module):\n",
        "    def __init__(self, bs, input_size, hidden_size, nonlinearity='tanh', return_sequences=False):\n",
        "        super().__init__()\n",
        "        self.i_h = nn.Linear(input_size, hidden_size)\n",
        "        self.h_h = nn.Linear(hidden_size, hidden_size)\n",
        "        self.nonlinearity = nonlinearity\n",
        "        self.return_sequences = return_sequences\n",
        "        self.h = torch.zeros((bs, hidden_size)) # (bs, hidden_size)\n",
        "\n",
        "    def forward(self, x): # (bs, seq_len, input_size)\n",
        "        seq_len = x.shape[1]\n",
        "        all_hidden_states = []\n",
        "        for i in range(seq_len):\n",
        "            i_h = self.i_h(x[:, i]) # (bs, hidden_size)\n",
        "            h_h = self.h_h(self.h) # (bs, hidden_size)\n",
        "            if self.nonlinearity == 'tanh':\n",
        "                self.h = torch.tanh(i_h + h_h) # (bs, hidden_size)\n",
        "            else:\n",
        "                self.h = torch.relu(i_h + h_h) # (bs, hidden_size)\n",
        "            all_hidden_states.append(self.h)\n",
        "        if self.return_sequences:\n",
        "            y = torch.stack(all_hidden_states, dim=1) # (bs, seq_len, hidden_size)\n",
        "        else:\n",
        "            y = all_hidden_states[-1] # (bs, hidden_size)\n",
        "        self.h = self.h.detach()\n",
        "        return y\n",
        "\n",
        "    def reset(self):\n",
        "        self.h = self.h.zero_()"
      ],
      "metadata": {
        "id": "_bcttAyXkiy1"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel3Alt(nn.Module):\n",
        "    def __init__(self, bs, vocab_size, input_emb_size, hidden_size, nonlinearity='tanh', return_sequences=False):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, input_emb_size)\n",
        "        self.rnn = SimpleRNNStateful(bs, input_emb_size, hidden_size, nonlinearity=nonlinearity, return_sequences=return_sequences)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x): # (bs, seq_len)\n",
        "        input_emb = self.emb(x) # (bs, seq_len, input_emb_size)\n",
        "        y = self.rnn(input_emb) # (bs, seq_len, hidden_size) if return_sequences == True else (bs, hidden_size)\n",
        "        return self.linear(y) # (bs, seq_len, vocab_size) if return_sequences == True else (bs, vocab_size)\n",
        "\n",
        "    def reset(self):\n",
        "        self.rnn.reset()"
      ],
      "metadata": {
        "id": "ZP9VghAsnCpT"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel3Alt2(nn.Module):\n",
        "    def __init__(self, bs, vocab_size, input_emb_size, hidden_size, nonlinearity='tanh', return_sequences=False):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, input_emb_size)\n",
        "        self.rnn = nn.RNNCell(input_emb_size, hidden_size, nonlinearity=nonlinearity)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "        self.return_sequences = return_sequences\n",
        "        self.h = torch.zeros((bs, hidden_size)) # (bs, hidden_size)\n",
        "\n",
        "    def forward(self, x): # (bs, seq_len)\n",
        "        input_emb = self.emb(x) # (bs, seq_len, input_emb_size)\n",
        "        seq_len = x.shape[1]\n",
        "        all_hidden_states = []\n",
        "        for i in range(seq_len):\n",
        "            self.h = self.rnn(input_emb[:, i], self.h) # (bs, hidden_size)\n",
        "            all_hidden_states.append(self.h)\n",
        "        if self.return_sequences:\n",
        "            y = torch.stack(all_hidden_states, dim=1) # (bs, seq_len, hidden_size)\n",
        "        else:\n",
        "            y = all_hidden_states[-1] # (bs, hidden_size)\n",
        "        output = self.linear(y) # (bs, seq_len, vocab_size) if return_sequences == True else (bs, vocab_size)\n",
        "        self.h = self.h.detach()\n",
        "        return output\n",
        "\n",
        "    def reset(self):\n",
        "        self.h = self.h.zero_()"
      ],
      "metadata": {
        "id": "rWU1GpXn0hJD"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel3Alt3(nn.Module):\n",
        "    def __init__(self, bs, vocab_size, input_emb_size, hidden_size, nonlinearity='tanh', return_sequences=False):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, input_emb_size)\n",
        "        self.rnn = nn.RNN(input_emb_size, hidden_size, num_layers=1, nonlinearity=nonlinearity, batch_first=True, dropout=0.0, bidirectional=False)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "        self.return_sequences = return_sequences\n",
        "        self.h = torch.zeros((1, bs, hidden_size))\n",
        "        # self.h is the initial hidden state with shape (D * 1, bs, hidden_size); 1 is the number of layers.\n",
        "        # D = 2 if bidirectional == True else 1.\n",
        "\n",
        "    def forward(self, x): # (bs, seq_len)\n",
        "        input_emb = self.emb(x) # (bs, seq_len, input_emb_size)\n",
        "        y, self.h = self.rnn(input_emb, self.h) # (bs, seq_len, hidden_size) is the shape of y.\n",
        "        # self.h is the last hidden state with shape (D * 1, bs, hidden_size); 1 is the number of layers.\n",
        "        # D = 2 if bidirectional == True else 1.\n",
        "        if not self.return_sequences:\n",
        "            y = y[:, -1] # (bs, hidden_size) if return_sequences == False\n",
        "        output = self.linear(y) # (bs, seq_len, vocab_size) if return_sequences == True else (bs, vocab_size)\n",
        "        self.h = self.h.detach()\n",
        "        return output\n",
        "\n",
        "    def reset(self):\n",
        "        self.h = self.h.zero_()"
      ],
      "metadata": {
        "id": "X0VYO_br5iet"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reminder:\n",
        "seqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfqsXPYLGbBE",
        "outputId": "c903632c-6f90-44f5-a76d-24783c9fc9fc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21031) [(tensor([0, 1, 2]), 1),(tensor([1, 3, 1]), 4),(tensor([4, 1, 5]), 1),(tensor([1, 6, 1]), 7),(tensor([7, 1, 8]), 1),(tensor([1, 9, 1]), 10),(tensor([10,  1, 11]), 1),(tensor([ 1, 12,  1]), 13),(tensor([13,  1, 14]), 1),(tensor([ 1, 15,  1]), 16)...]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reminder:\n",
        "bs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV6u3k1eHU_O",
        "outputId": "aa3c6905-dd11-4fe2-9499-bdfda5a159c9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = len(seqs) // bs\n",
        "m, bs, len(seqs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvhGcQk9HX5P",
        "outputId": "25658b6d-c541-41c6-d2cb-36635d7a2990"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(657, 32, 21031)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** `m` will be the number of batches."
      ],
      "metadata": {
        "id": "p2ZGdKPSDAc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "657 * 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg0aJQSSHdae",
        "outputId": "ab6dd176-1388-486d-a5b9-987c269b9869"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21024"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last few **samples** will be dropped.\n",
        "\n",
        "**Note:** Each element of the `seqs` dataset is a **sample of three tokens**, not a single token."
      ],
      "metadata": {
        "id": "yqH50tIXCWWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "V4Bwr6PGfGou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_chunks(ds, bs):\n",
        "    m = len(ds) // bs\n",
        "    new_ds = L()\n",
        "    for i in range(m):\n",
        "        new_ds += L(ds[i + m * j] for j in range(bs))\n",
        "    return new_ds"
      ],
      "metadata": {
        "id": "2U9P3sf4Ib_6"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first batch will be composed of the samples `(0, m, 2 * m, ..., (bs - 1) * m)`, the second batch will be composed of the samples `(1, m + 1, 2 * m + 1, ..., (bs - 1) * m + 1)`, and so on... The inner loop is going down the columns. The outer loop is going across the rows."
      ],
      "metadata": {
        "id": "ZCJN_80nGKSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rearranged_seqs = group_chunks(seqs, bs)\n",
        "rearranged_seqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSjS_ga1JB4E",
        "outputId": "be7ed948-708f-49a8-c6f6-d83e9b30e188"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#21024) [(tensor([0, 1, 2]), 1),(tensor([ 1,  4, 28]), 24),(tensor([26,  1,  8]), 28),(tensor([ 1,  0, 29]), 2),(tensor([4, 1, 0]), 29),(tensor([20,  8,  1]), 0),(tensor([23,  0,  1]), 2),(tensor([28, 22,  5]), 1),(tensor([ 7, 28, 21]), 9),(tensor([ 1,  3, 29]), 22)...]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rearranged_seqs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyjODfNEJH56",
        "outputId": "19809a92-3e65-4ed3-ba73-4ae012747e98"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2]), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rearranged_seqs[32]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDs1wNO8JOAZ",
        "outputId": "62d138ad-9862-44a9-ab42-d933279f9c87"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 3, 1]), 4)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The second element in `seqs` has become the thirty third element in `rearranged_seqs`."
      ],
      "metadata": {
        "id": "4AJ-QhCVB4P6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cut = int(len(seqs) * 0.8)\n",
        "cut"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN3u25bLJ0oa",
        "outputId": "b51fa7d2-57e8-48ab-fce3-0865de41c24d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16824"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dls = DataLoaders.from_dsets(\n",
        "    group_chunks(seqs[:cut], bs),\n",
        "    group_chunks(seqs[cut:], bs),\n",
        "    bs=bs,\n",
        "    drop_last=True,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "5kAg87GCJ4wP"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "16824 // 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUqMKtb-KKMp",
        "outputId": "70d63d8f-9f6e-483c-935e-8b06eea15ef5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "525"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dls.train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts1b8SULKMwz",
        "outputId": "1aed0771-06d7-43d4-df07-dcf717457923"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "525"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(dls.train))\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW1JUsU9KOu1",
        "outputId": "c0a99a80-ae77-4378-ba5e-8d6e0a9b8e2a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LMModel3(len(vocab), 64)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjHrXhYWKfcl",
        "outputId": "273a85db-2a4e-4774-ca4d-9b72e300047f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel3(\n",
              "  (i_h): Embedding(30, 64)\n",
              "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (h_o): Linear(in_features=64, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    output = model(x)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwjlrSZtKjB4",
        "outputId": "71eef9d2-2275-4fb8-8e7c-3f37cf843ad1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt = LMModel3Alt(bs=bs, vocab_size=len(vocab), input_emb_size=64, hidden_size=128, nonlinearity='tanh', return_sequences=False)\n",
        "model_alt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeM2ZfHOrVDf",
        "outputId": "b73f7f85-c4d3-4835-b689-4514fc83e71d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel3Alt(\n",
              "  (emb): Embedding(30, 64)\n",
              "  (rnn): SimpleRNNStateful(\n",
              "    (i_h): Linear(in_features=64, out_features=128, bias=True)\n",
              "    (h_h): Linear(in_features=128, out_features=128, bias=True)\n",
              "  )\n",
              "  (linear): Linear(in_features=128, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    output = model_alt(x)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChFFfyIDrmGE",
        "outputId": "be2cc000-12cd-497a-cf1b-dfe5a5fdd02c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt2 = LMModel3Alt2(bs=bs, vocab_size=len(vocab), input_emb_size=64, hidden_size=128, nonlinearity='tanh', return_sequences=False)\n",
        "model_alt2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejbFmM71tiSm",
        "outputId": "606f5a1d-fb66-4b89-a7ae-75aabd203f6f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel3Alt2(\n",
              "  (emb): Embedding(30, 64)\n",
              "  (rnn): RNNCell(64, 128)\n",
              "  (linear): Linear(in_features=128, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    output = model_alt2(x)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfXpv9RftxNM",
        "outputId": "74701d61-0a31-4f4c-dabe-bc6073d586d5"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt3 = LMModel3Alt3(bs=bs, vocab_size=len(vocab), input_emb_size=64, hidden_size=128, nonlinearity='tanh', return_sequences=False)\n",
        "model_alt3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v6l7pByydeB",
        "outputId": "b718e215-8510-4b7b-9df2-e23d717716b7"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel3Alt3(\n",
              "  (emb): Embedding(30, 64)\n",
              "  (rnn): RNN(64, 128, batch_first=True)\n",
              "  (linear): Linear(in_features=128, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    output = model_alt3(x)\n",
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO_i9UVwytHc",
        "outputId": "047964b1-2496-4436-b27d-caa32703b622"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset()\n",
        "learn = Learner(dls, model, loss_func=F.cross_entropy, metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(10, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "QeMyBNNcKp0B",
        "outputId": "c4ff9150-5ecf-4a2f-ec8a-0bbafaa60968"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.498798</td>\n",
              "      <td>1.742323</td>\n",
              "      <td>0.484256</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.164119</td>\n",
              "      <td>1.689535</td>\n",
              "      <td>0.453960</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.027975</td>\n",
              "      <td>1.718138</td>\n",
              "      <td>0.495229</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.972684</td>\n",
              "      <td>1.877180</td>\n",
              "      <td>0.543416</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.952699</td>\n",
              "      <td>1.813588</td>\n",
              "      <td>0.553674</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.947687</td>\n",
              "      <td>1.723938</td>\n",
              "      <td>0.536021</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.941458</td>\n",
              "      <td>1.759222</td>\n",
              "      <td>0.544609</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.910977</td>\n",
              "      <td>1.705199</td>\n",
              "      <td>0.560353</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.873374</td>\n",
              "      <td>1.818613</td>\n",
              "      <td>0.567032</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.854535</td>\n",
              "      <td>1.848573</td>\n",
              "      <td>0.567271</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt.reset()\n",
        "learn = Learner(dls, model_alt, loss_func=F.cross_entropy, metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(10, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "0P3uxAYer_qa",
        "outputId": "0b6638d9-77fe-4f3c-f8e6-c46ff503ab31"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.478031</td>\n",
              "      <td>1.730701</td>\n",
              "      <td>0.455630</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.082841</td>\n",
              "      <td>1.636926</td>\n",
              "      <td>0.458492</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.985360</td>\n",
              "      <td>1.658197</td>\n",
              "      <td>0.509065</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.962140</td>\n",
              "      <td>1.624847</td>\n",
              "      <td>0.529103</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.970779</td>\n",
              "      <td>1.615860</td>\n",
              "      <td>0.537691</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.939001</td>\n",
              "      <td>1.525761</td>\n",
              "      <td>0.555105</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.942902</td>\n",
              "      <td>1.486618</td>\n",
              "      <td>0.561546</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.914602</td>\n",
              "      <td>1.475283</td>\n",
              "      <td>0.570611</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.858734</td>\n",
              "      <td>1.454241</td>\n",
              "      <td>0.592080</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.838070</td>\n",
              "      <td>1.466927</td>\n",
              "      <td>0.596135</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt2.reset()\n",
        "learn = Learner(dls, model_alt2, loss_func=F.cross_entropy, metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(10, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "NrJjEr-Pt8k0",
        "outputId": "3d341a98-07a0-4e4d-ede7-e328a9592875"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.471323</td>\n",
              "      <td>1.710472</td>\n",
              "      <td>0.487834</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.069962</td>\n",
              "      <td>1.621686</td>\n",
              "      <td>0.480677</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.999121</td>\n",
              "      <td>1.569430</td>\n",
              "      <td>0.523378</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.988791</td>\n",
              "      <td>1.607360</td>\n",
              "      <td>0.543416</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.913061</td>\n",
              "      <td>1.554841</td>\n",
              "      <td>0.560353</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.979376</td>\n",
              "      <td>1.487215</td>\n",
              "      <td>0.548187</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.944388</td>\n",
              "      <td>1.421582</td>\n",
              "      <td>0.560115</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.932041</td>\n",
              "      <td>1.454480</td>\n",
              "      <td>0.573712</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.889424</td>\n",
              "      <td>1.434849</td>\n",
              "      <td>0.586594</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.855925</td>\n",
              "      <td>1.448068</td>\n",
              "      <td>0.595420</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt3.reset()\n",
        "learn = Learner(dls, model_alt3, loss_func=F.cross_entropy, metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(10, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "V_zG5EW4y5Xt",
        "outputId": "7d9d41cb-4656-4437-d620-1cd8a645e867"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.483872</td>\n",
              "      <td>1.787058</td>\n",
              "      <td>0.401718</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.080464</td>\n",
              "      <td>1.602044</td>\n",
              "      <td>0.475906</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.011189</td>\n",
              "      <td>1.622901</td>\n",
              "      <td>0.461832</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.991889</td>\n",
              "      <td>1.622690</td>\n",
              "      <td>0.529819</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.970380</td>\n",
              "      <td>1.599558</td>\n",
              "      <td>0.541746</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.959774</td>\n",
              "      <td>1.558498</td>\n",
              "      <td>0.536260</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.944571</td>\n",
              "      <td>1.519980</td>\n",
              "      <td>0.565363</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.913819</td>\n",
              "      <td>1.359177</td>\n",
              "      <td>0.566078</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.871988</td>\n",
              "      <td>1.435637</td>\n",
              "      <td>0.578244</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.840539</td>\n",
              "      <td>1.472258</td>\n",
              "      <td>0.587071</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoIwl1rca7Ub"
      },
      "source": [
        "### Creating More Signal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sl = 16\n",
        "seqs = L((tensor(nums[i:i + sl]), tensor(nums[i + 1:i + sl + 1])) for i in range(0, len(nums) - sl - 1, sl))\n",
        "seqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xerRoYlFTa7L",
        "outputId": "42f5a60a-7a78-4276-b457-2da364978b2b"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3943) [(tensor([0, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, 7, 1, 8, 1]), tensor([1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, 7, 1, 8, 1, 9])),(tensor([ 9,  1, 10,  1, 11,  1, 12,  1, 13,  1, 14,  1, 15,  1, 16,  1]), tensor([ 1, 10,  1, 11,  1, 12,  1, 13,  1, 14,  1, 15,  1, 16,  1, 17])),(tensor([17,  1, 18,  1, 19,  1, 20,  1, 20,  0,  1, 20,  2,  1, 20,  3]), tensor([ 1, 18,  1, 19,  1, 20,  1, 20,  0,  1, 20,  2,  1, 20,  3,  1])),(tensor([ 1, 20,  4,  1, 20,  5,  1, 20,  6,  1, 20,  7,  1, 20,  8,  1]), tensor([20,  4,  1, 20,  5,  1, 20,  6,  1, 20,  7,  1, 20,  8,  1, 20])),(tensor([20,  9,  1, 21,  1, 21,  0,  1, 21,  2,  1, 21,  3,  1, 21,  4]), tensor([ 9,  1, 21,  1, 21,  0,  1, 21,  2,  1, 21,  3,  1, 21,  4,  1])),(tensor([ 1, 21,  5,  1, 21,  6,  1, 21,  7,  1, 21,  8,  1, 21,  9,  1]), tensor([21,  5,  1, 21,  6,  1, 21,  7,  1, 21,  8,  1, 21,  9,  1, 22])),(tensor([22,  1, 22,  0,  1, 22,  2,  1, 22,  3,  1, 22,  4,  1, 22,  5]), tensor([ 1, 22,  0,  1, 22,  2,  1, 22,  3,  1, 22,  4,  1, 22,  5,  1])),(tensor([ 1, 22,  6,  1, 22,  7,  1, 22,  8,  1, 22,  9,  1, 23,  1, 23]), tensor([22,  6,  1, 22,  7,  1, 22,  8,  1, 22,  9,  1, 23,  1, 23,  0])),(tensor([ 0,  1, 23,  2,  1, 23,  3,  1, 23,  4,  1, 23,  5,  1, 23,  6]), tensor([ 1, 23,  2,  1, 23,  3,  1, 23,  4,  1, 23,  5,  1, 23,  6,  1])),(tensor([ 1, 23,  7,  1, 23,  8,  1, 23,  9,  1, 24,  1, 24,  0,  1, 24]), tensor([23,  7,  1, 23,  8,  1, 23,  9,  1, 24,  1, 24,  0,  1, 24,  2]))...]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seqs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVBtuprjTyfy",
        "outputId": "c0941910-b650-4b87-c481-e57cfaf29ed6"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, 7, 1, 8, 1]),\n",
              " tensor([1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, 7, 1, 8, 1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cut = int(len(seqs) * 0.8)\n",
        "dls = DataLoaders.from_dsets(\n",
        "    group_chunks(seqs[:cut], bs),\n",
        "    group_chunks(seqs[cut:], bs),\n",
        "    bs=bs,\n",
        "    drop_last=True,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "9fdQ9WtPT4tS"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(dls.train))\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed2e2--XUH65",
        "outputId": "e034fbb5-b592-46d5-f224-738dbe1517c4"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 16]), torch.Size([32, 16]))"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reminder:\n",
        "seqs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiP1p8VKUNUu",
        "outputId": "ae987b58-5ca4-488c-f9e2-16c47f44549d"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, 7, 1, 8, 1]),\n",
              " tensor([1, 2, 1, 3, 1, 4, 1, 5, 1, 6, 1, 7, 1, 8, 1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reminder:\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McReXYxDUbrZ",
        "outputId": "d6c64ead-4a36-4e0c-f998-43f16d75250e"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#30) ['one','.','two','three','four','five','six','seven','eight','nine'...]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[L(vocab[o] for o in s) for s in seqs[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFBMLv3HUPrx",
        "outputId": "7f7c50cb-bf7b-4e1c-ee32-ee91418f8613"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(#16) ['one','.','two','.','three','.','four','.','five','.'...],\n",
              " (#16) ['.','two','.','three','.','four','.','five','.','six'...]]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LMModel4(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        outs = []\n",
        "        for i in range(sl):\n",
        "            self.h = self.h + self.i_h(x[:, i])\n",
        "            self.h = F.relu(self.h_h(self.h))\n",
        "            outs.append(self.h_o(self.h))\n",
        "        self.h = self.h.detach()\n",
        "        return torch.stack(outs, dim=1)\n",
        "\n",
        "    def reset(self):\n",
        "        self.h = 0"
      ],
      "metadata": {
        "id": "Y4lMNyKbUmdx"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** `sl` is being picked up from the global namespace."
      ],
      "metadata": {
        "id": "k_nyycXZ5xGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LMModel4(len(vocab), 64)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1t6gNa9VlYN",
        "outputId": "4c0c6fba-22c4-4c89-c2dd-0113140ed7cf"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel4(\n",
              "  (i_h): Embedding(30, 64)\n",
              "  (h_h): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (h_o): Linear(in_features=64, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    logits = model(x)\n",
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4K7AdEoVyIM",
        "outputId": "acbe7a31-b57e-45ad-bf22-23628e0e21f2"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 16, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets = y\n",
        "targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81gIO0UcV5mJ",
        "outputId": "1cc57ecd-2db7-46c9-e846-2c755e7faf52"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use `F.cross_entropy`, we need to reshape the logits and targets."
      ],
      "metadata": {
        "id": "ZKAS_tuC74tM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits.view(-1, len(vocab)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LowyzLBpV-IV",
        "outputId": "39f7fa67-87bb-4a71-c9c6-bb53b21558b2"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets.view(-1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hemw8JF4WCpQ",
        "outputId": "35fc47ce-ab48-47ac-8f3f-5ba6c933d1b8"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([512])"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(inp, targ):\n",
        "    return F.cross_entropy(inp.view(-1, len(vocab)), targ.view(-1))"
      ],
      "metadata": {
        "id": "Nx_LigxsWFRK"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset()\n",
        "learn = Learner(dls, model, loss_func=loss_func, metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "bPKP87YpWPX6",
        "outputId": "8b0f8088-1a02-46a3-886a-cc03f9bc6385"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.820750</td>\n",
              "      <td>2.493289</td>\n",
              "      <td>0.305257</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.715505</td>\n",
              "      <td>1.843506</td>\n",
              "      <td>0.411621</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.413977</td>\n",
              "      <td>1.848683</td>\n",
              "      <td>0.463135</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.216401</td>\n",
              "      <td>1.681567</td>\n",
              "      <td>0.482666</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.035639</td>\n",
              "      <td>1.571302</td>\n",
              "      <td>0.481527</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.837167</td>\n",
              "      <td>1.606419</td>\n",
              "      <td>0.500163</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.706436</td>\n",
              "      <td>1.510629</td>\n",
              "      <td>0.525635</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.627138</td>\n",
              "      <td>1.327492</td>\n",
              "      <td>0.582031</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.560145</td>\n",
              "      <td>1.194417</td>\n",
              "      <td>0.622396</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.514664</td>\n",
              "      <td>1.275698</td>\n",
              "      <td>0.615804</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.441902</td>\n",
              "      <td>1.193281</td>\n",
              "      <td>0.675212</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.404962</td>\n",
              "      <td>1.251495</td>\n",
              "      <td>0.653402</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.400040</td>\n",
              "      <td>1.252682</td>\n",
              "      <td>0.653646</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.362876</td>\n",
              "      <td>1.306476</td>\n",
              "      <td>0.651855</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.351005</td>\n",
              "      <td>1.267531</td>\n",
              "      <td>0.657145</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt = LMModel3Alt(bs=bs, vocab_size=len(vocab), input_emb_size=64, hidden_size=128, nonlinearity='tanh', return_sequences=True)\n",
        "model_alt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NHBVdlyXj_s",
        "outputId": "5dbd5769-627f-4f90-c619-04094c211909"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel3Alt(\n",
              "  (emb): Embedding(30, 64)\n",
              "  (rnn): SimpleRNNStateful(\n",
              "    (i_h): Linear(in_features=64, out_features=128, bias=True)\n",
              "    (h_h): Linear(in_features=128, out_features=128, bias=True)\n",
              "  )\n",
              "  (linear): Linear(in_features=128, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    logits = model_alt(x)\n",
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQzSeu7ZXnDs",
        "outputId": "8e1c96d9-f071-445e-d166-ba535f1c251c"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 16, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt.reset()\n",
        "learn = Learner(dls, model_alt, loss_func=loss_func, metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "c5dUev7hXxxY",
        "outputId": "27ab7d73-6623-40ce-a887-6ab27db793da"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.299101</td>\n",
              "      <td>1.929870</td>\n",
              "      <td>0.471598</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.605652</td>\n",
              "      <td>1.860847</td>\n",
              "      <td>0.367839</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.405675</td>\n",
              "      <td>1.843909</td>\n",
              "      <td>0.485189</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.197719</td>\n",
              "      <td>1.753207</td>\n",
              "      <td>0.529460</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.000475</td>\n",
              "      <td>1.552671</td>\n",
              "      <td>0.578288</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.848223</td>\n",
              "      <td>1.498886</td>\n",
              "      <td>0.604574</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.716819</td>\n",
              "      <td>1.518034</td>\n",
              "      <td>0.622233</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.614500</td>\n",
              "      <td>1.530645</td>\n",
              "      <td>0.626383</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.552015</td>\n",
              "      <td>1.586838</td>\n",
              "      <td>0.636882</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.487866</td>\n",
              "      <td>1.564973</td>\n",
              "      <td>0.665120</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.468924</td>\n",
              "      <td>1.535064</td>\n",
              "      <td>0.641195</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.429244</td>\n",
              "      <td>1.546590</td>\n",
              "      <td>0.676758</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.397417</td>\n",
              "      <td>1.582017</td>\n",
              "      <td>0.679606</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.380445</td>\n",
              "      <td>1.597348</td>\n",
              "      <td>0.674398</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.372932</td>\n",
              "      <td>1.618718</td>\n",
              "      <td>0.674235</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt2 = LMModel3Alt2(bs=bs, vocab_size=len(vocab), input_emb_size=64, hidden_size=128, nonlinearity='tanh', return_sequences=True)\n",
        "model_alt2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1jfd7UCYE55",
        "outputId": "e5f5f4d8-1280-4a72-f7e8-d4e9fef3a608"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel3Alt2(\n",
              "  (emb): Embedding(30, 64)\n",
              "  (rnn): RNNCell(64, 128)\n",
              "  (linear): Linear(in_features=128, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    logits = model_alt2(x)\n",
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mote4zCYLMa",
        "outputId": "4fb358e5-9333-4cbe-c940-4697dd81d0b6"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 16, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt2.reset()\n",
        "learn = Learner(dls, model_alt2, loss_func=loss_func, metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "Q8YzlgiJYWUu",
        "outputId": "4b542bdb-3e2a-4449-aaab-7efb2b386ac9"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.388109</td>\n",
              "      <td>1.987374</td>\n",
              "      <td>0.466390</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.611572</td>\n",
              "      <td>1.787286</td>\n",
              "      <td>0.459961</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.382553</td>\n",
              "      <td>1.831302</td>\n",
              "      <td>0.487630</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.200116</td>\n",
              "      <td>1.835692</td>\n",
              "      <td>0.510498</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.019086</td>\n",
              "      <td>1.835817</td>\n",
              "      <td>0.548747</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.857534</td>\n",
              "      <td>1.794486</td>\n",
              "      <td>0.569336</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.733162</td>\n",
              "      <td>1.894485</td>\n",
              "      <td>0.580322</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.634630</td>\n",
              "      <td>1.890308</td>\n",
              "      <td>0.578613</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.561239</td>\n",
              "      <td>1.878065</td>\n",
              "      <td>0.594157</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.501314</td>\n",
              "      <td>1.894531</td>\n",
              "      <td>0.618815</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.455128</td>\n",
              "      <td>2.000217</td>\n",
              "      <td>0.622233</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.425018</td>\n",
              "      <td>1.919862</td>\n",
              "      <td>0.646566</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.387774</td>\n",
              "      <td>1.949576</td>\n",
              "      <td>0.637451</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.365712</td>\n",
              "      <td>1.970119</td>\n",
              "      <td>0.638265</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.355193</td>\n",
              "      <td>1.985512</td>\n",
              "      <td>0.634277</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt3 = LMModel3Alt3(bs=bs, vocab_size=len(vocab), input_emb_size=64, hidden_size=128, nonlinearity='tanh', return_sequences=True)\n",
        "model_alt3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaZ3kYt6Ymgo",
        "outputId": "bb202d22-0cd2-4429-9936-77c6027d66e2"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LMModel3Alt3(\n",
              "  (emb): Embedding(30, 64)\n",
              "  (rnn): RNN(64, 128, batch_first=True)\n",
              "  (linear): Linear(in_features=128, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test:\n",
        "with torch.no_grad():\n",
        "    logits = model_alt3(x)\n",
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i45QlKrtYpuA",
        "outputId": "4d78a1a0-4b0d-4d21-c027-80f663bad28c"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 16, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_alt3.reset()\n",
        "learn = Learner(dls, model_alt3, loss_func=loss_func, metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "1m7v8RBwYuah",
        "outputId": "6cea36ff-3858-45c5-de75-876ad5b18a89"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2.345664</td>\n",
              "      <td>1.923041</td>\n",
              "      <td>0.467855</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.613324</td>\n",
              "      <td>1.861885</td>\n",
              "      <td>0.398926</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.373003</td>\n",
              "      <td>1.744215</td>\n",
              "      <td>0.497070</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.152012</td>\n",
              "      <td>1.717458</td>\n",
              "      <td>0.499105</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.974674</td>\n",
              "      <td>1.758620</td>\n",
              "      <td>0.540446</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.822125</td>\n",
              "      <td>1.801135</td>\n",
              "      <td>0.587158</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.691558</td>\n",
              "      <td>1.847366</td>\n",
              "      <td>0.618734</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.590517</td>\n",
              "      <td>1.768564</td>\n",
              "      <td>0.618327</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.509639</td>\n",
              "      <td>1.859188</td>\n",
              "      <td>0.629557</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.461319</td>\n",
              "      <td>1.895708</td>\n",
              "      <td>0.643717</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.419729</td>\n",
              "      <td>1.888450</td>\n",
              "      <td>0.658691</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.387504</td>\n",
              "      <td>1.815918</td>\n",
              "      <td>0.652344</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.355204</td>\n",
              "      <td>1.851539</td>\n",
              "      <td>0.648763</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.338330</td>\n",
              "      <td>1.844075</td>\n",
              "      <td>0.652832</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.329474</td>\n",
              "      <td>1.863694</td>\n",
              "      <td>0.647542</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOHOnVgua7Uc"
      },
      "source": [
        "## Multilayer RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPf9algaa7Uc"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75oCx-_fa7Uc"
      },
      "outputs": [],
      "source": [
        "class LMModel5(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.RNN(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = torch.zeros(n_layers, bs, n_hidden) # bs is being picked up from the global namespace.\n",
        "\n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = h.detach()\n",
        "        return self.h_o(res)\n",
        "\n",
        "    def reset(self): self.h.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As in stateful RNNs in Keras, this network only works with a particular batch size."
      ],
      "metadata": {
        "id": "a_RD2pm_nbGl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3J1n84Iua7Ui"
      },
      "outputs": [],
      "source": [
        "learn = Learner(dls, LMModel5(len(vocab), 64, 2),\n",
        "                loss_func=CrossEntropyLossFlat(),\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 3e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SclCaj6a7Ui"
      },
      "source": [
        "### Exploding or Disappearing Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APQw4JuVa7Ui"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pus4Lbb9a7Ui"
      },
      "source": [
        "### Building an LSTM from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LBiqM4-a7Ui"
      },
      "outputs": [],
      "source": [
        "class LSTMCell(Module):\n",
        "    def __init__(self, ni, nh):\n",
        "        self.forget_gate = nn.Linear(ni + nh, nh)\n",
        "        self.input_gate  = nn.Linear(ni + nh, nh)\n",
        "        self.cell_gate   = nn.Linear(ni + nh, nh)\n",
        "        self.output_gate = nn.Linear(ni + nh, nh)\n",
        "\n",
        "    def forward(self, input, state):\n",
        "        h,c = state\n",
        "        h = torch.cat([h, input], dim=1)\n",
        "        forget = torch.sigmoid(self.forget_gate(h))\n",
        "        c = c * forget\n",
        "        inp = torch.sigmoid(self.input_gate(h))\n",
        "        cell = torch.tanh(self.cell_gate(h))\n",
        "        c = c + inp * cell\n",
        "        out = torch.sigmoid(self.output_gate(h))\n",
        "        h = out * torch.tanh(c)\n",
        "        return h, (h,c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko22FWdpa7Ui"
      },
      "outputs": [],
      "source": [
        "class LSTMCell(Module):\n",
        "    def __init__(self, ni, nh):\n",
        "        self.ih = nn.Linear(ni,4*nh)\n",
        "        self.hh = nn.Linear(nh,4*nh)\n",
        "\n",
        "    def forward(self, input, state):\n",
        "        h,c = state\n",
        "        # One big multiplication for all the gates is better than 4 smaller ones\n",
        "        gates = (self.ih(input) + self.hh(h)).chunk(4, 1)\n",
        "        ingate,forgetgate,outgate = map(torch.sigmoid, gates[:3])\n",
        "        cellgate = gates[3].tanh()\n",
        "\n",
        "        c = (forgetgate*c) + (ingate*cellgate)\n",
        "        h = outgate * c.tanh()\n",
        "        return h, (h,c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgRIB_dKa7Uj"
      },
      "outputs": [],
      "source": [
        "t = torch.arange(0,10); t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp-U8eVsa7Uj"
      },
      "outputs": [],
      "source": [
        "t.chunk(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbtYzmi5a7Uj"
      },
      "source": [
        "### Training a Language Model Using LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJNcmNwla7Uj"
      },
      "outputs": [],
      "source": [
        "class LMModel6(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        res,h = self.rnn(self.i_h(x), self.h)\n",
        "        self.h = [h_.detach() for h_ in h]\n",
        "        return self.h_o(res)\n",
        "\n",
        "    def reset(self):\n",
        "        for h in self.h: h.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAGwLszBa7Uj"
      },
      "outputs": [],
      "source": [
        "learn = Learner(dls, LMModel6(len(vocab), 64, 2),\n",
        "                loss_func=CrossEntropyLossFlat(),\n",
        "                metrics=accuracy, cbs=ModelResetter)\n",
        "learn.fit_one_cycle(15, 1e-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVFucYnda7Uj"
      },
      "source": [
        "## Regularizing an LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDAWOpCXa7Uj"
      },
      "source": [
        "### Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNLQv3_Ba7Uj"
      },
      "outputs": [],
      "source": [
        "class Dropout(Module):\n",
        "    def __init__(self, p): self.p = p\n",
        "    def forward(self, x):\n",
        "        if not self.training: return x\n",
        "        mask = x.new(*x.shape).bernoulli_(1-p)\n",
        "        return x * mask.div_(1-p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO-LACXaa7Uj"
      },
      "source": [
        "### Activation Regularization and Temporal Activation Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBZJW5PKa7Uj"
      },
      "source": [
        "### Training a Weight-Tied Regularized LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QVzHuIDa7Uj"
      },
      "outputs": [],
      "source": [
        "class LMModel7(Module):\n",
        "    def __init__(self, vocab_sz, n_hidden, n_layers, p):\n",
        "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
        "        self.rnn = nn.LSTM(n_hidden, n_hidden, n_layers, batch_first=True)\n",
        "        self.drop = nn.Dropout(p)\n",
        "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
        "        self.h_o.weight = self.i_h.weight\n",
        "        self.h = [torch.zeros(n_layers, bs, n_hidden) for _ in range(2)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        raw,h = self.rnn(self.i_h(x), self.h)\n",
        "        out = self.drop(raw)\n",
        "        self.h = [h_.detach() for h_ in h]\n",
        "        return self.h_o(out),raw,out\n",
        "\n",
        "    def reset(self):\n",
        "        for h in self.h: h.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W32SKg3ma7Uk"
      },
      "outputs": [],
      "source": [
        "learn = Learner(dls, LMModel7(len(vocab), 64, 2, 0.5),\n",
        "                loss_func=CrossEntropyLossFlat(), metrics=accuracy,\n",
        "                cbs=[ModelResetter, RNNRegularizer(alpha=2, beta=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efyPz0xca7Uk"
      },
      "outputs": [],
      "source": [
        "learn = TextLearner(dls, LMModel7(len(vocab), 64, 2, 0.4),\n",
        "                    loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIBatbc2a7Uk"
      },
      "outputs": [],
      "source": [
        "learn.fit_one_cycle(15, 1e-2, wd=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOpg2vb1a7Uk"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTdgCa30a7Uk"
      },
      "source": [
        "## Questionnaire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkJaZci3a7Uk"
      },
      "source": [
        "1. If the dataset for your project is so big and complicated that working with it takes a significant amount of time, what should you do?\n",
        "1. Why do we concatenate the documents in our dataset before creating a language model?\n",
        "1. To use a standard fully connected network to predict the fourth word given the previous three words, what two tweaks do we need to make to our model?\n",
        "1. How can we share a weight matrix across multiple layers in PyTorch?\n",
        "1. Write a module that predicts the third word given the previous two words of a sentence, without peeking.\n",
        "1. What is a recurrent neural network?\n",
        "1. What is \"hidden state\"?\n",
        "1. What is the equivalent of hidden state in ` LMModel1`?\n",
        "1. To maintain the state in an RNN, why is it important to pass the text to the model in order?\n",
        "1. What is an \"unrolled\" representation of an RNN?\n",
        "1. Why can maintaining the hidden state in an RNN lead to memory and performance problems? How do we fix this problem?\n",
        "1. What is \"BPTT\"?\n",
        "1. Write code to print out the first few batches of the validation set, including converting the token IDs back into English strings, as we showed for batches of IMDb data in <<chapter_nlp>>.\n",
        "1. What does the `ModelResetter` callback do? Why do we need it?\n",
        "1. What are the downsides of predicting just one output word for each three input words?\n",
        "1. Why do we need a custom loss function for `LMModel4`?\n",
        "1. Why is the training of `LMModel4` unstable?\n",
        "1. In the unrolled representation, we can see that a recurrent neural network actually has many layers. So why do we need to stack RNNs to get better results?\n",
        "1. Draw a representation of a stacked (multilayer) RNN.\n",
        "1. Why should we get better results in an RNN if we call `detach` less often? Why might this not happen in practice with a simple RNN?\n",
        "1. Why can a deep network result in very large or very small activations? Why does this matter?\n",
        "1. In a computer's floating-point representation of numbers, which numbers are the most precise?\n",
        "1. Why do vanishing gradients prevent training?\n",
        "1. Why does it help to have two hidden states in the LSTM architecture? What is the purpose of each one?\n",
        "1. What are these two states called in an LSTM?\n",
        "1. What is tanh, and how is it related to sigmoid?\n",
        "1. What is the purpose of this code in `LSTMCell`: `h = torch.cat([h, input], dim=1)`\n",
        "1. What does `chunk` do in PyTorch?\n",
        "1. Study the refactored version of `LSTMCell` carefully to ensure you understand how and why it does the same thing as the non-refactored version.\n",
        "1. Why can we use a higher learning rate for `LMModel6`?\n",
        "1. What are the three regularization techniques used in an AWD-LSTM model?\n",
        "1. What is \"dropout\"?\n",
        "1. Why do we scale the acitvations with dropout? Is this applied during training, inference, or both?\n",
        "1. What is the purpose of this line from `Dropout`: `if not self.training: return x`\n",
        "1. Experiment with `bernoulli_` to understand how it works.\n",
        "1. How do you set your model in training mode in PyTorch? In evaluation mode?\n",
        "1. Write the equation for activation regularization (in math or code, as you prefer). How is it different from weight decay?\n",
        "1. Write the equation for temporal activation regularization (in math or code, as you prefer). Why wouldn't we use this for computer vision problems?\n",
        "1. What is \"weight tying\" in a language model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLt7p7BFa7Uk"
      },
      "source": [
        "### Further Research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KlmNpmpa7Uk"
      },
      "source": [
        "1. In ` LMModel2`, why can `forward` start with `h=0`? Why don't we need to say `h=torch.zeros(...)`?\n",
        "1. Write the code for an LSTM from scratch (you may refer to <<lstm>>).\n",
        "1. Search the internet for the GRU architecture and implement it from scratch, and try training a model. See if you can get results similar to those we saw in this chapter. Compare your results to the results of PyTorch's built in `GRU` module.\n",
        "1. Take a look at the source code for AWD-LSTM in fastai, and try to map each of the lines of code to the concepts shown in this chapter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H7r0cK-a7Uk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}